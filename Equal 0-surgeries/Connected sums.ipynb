{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will show that any connected sum with at most 9 crossings shares no 0-surgery with a knot of up to 19 crossings. For that we recall that the 0-surgery on a connected sum is a JSJ manifold. So we will first check all knots with the same Alexander polynomial for beeing non-hyperbolic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:181: DeprecationWarning: invalid escape sequence \\d\n",
      "<>:181: DeprecationWarning: invalid escape sequence \\d\n",
      "<ipython-input-1-cef6550c8024>:181: DeprecationWarning: invalid escape sequence \\d\n",
      "  match = re.search('(.*) : #\\d+$', name)\n"
     ]
    }
   ],
   "source": [
    "import snappy\n",
    "import regina\n",
    "import csv\n",
    "import time\n",
    "\n",
    "def all_positive(manifold):\n",
    "    '''\n",
    "    Checks if the solution type of a triangulation is positive.\n",
    "    '''\n",
    "    return manifold.solution_type() == 'all tetrahedra positively oriented'\n",
    "\n",
    "def find_positive_triangulations(manifold,number=1,tries=100):\n",
    "    '''\n",
    "    Searches for one triangulation with a positive solution type.\n",
    "    (Or if number is set to a different value also for different such triangulations.)\n",
    "    '''\n",
    "    M = manifold.copy()\n",
    "    pos_triangulations=[]\n",
    "    for i in range(tries):\n",
    "        if all_positive(M):\n",
    "            pos_triangulations.append(M)\n",
    "            if len(pos_triangulations)==number:\n",
    "                return pos_triangulations\n",
    "            break\n",
    "        M.randomize()\n",
    "    for d in M.dual_curves(max_segments=500):\n",
    "        X = M.drill(d)\n",
    "        X = X.filled_triangulation()\n",
    "        X.dehn_fill((1,0),-1)\n",
    "        for i in range(tries):\n",
    "            if all_positive(X):\n",
    "                pos_triangulations.append(X)\n",
    "                if len(pos_triangulations)==number:\n",
    "                    return pos_triangulations\n",
    "                break\n",
    "            X.randomize()\n",
    "\n",
    "    # In the closed case, here is another trick.\n",
    "    if all(not c for c in M.cusp_info('is_complete')):\n",
    "        for i in range(tries):\n",
    "            # Drills out a random edge\n",
    "            X = M.__class__(M.filled_triangulation())\n",
    "            if all_positive(X):\n",
    "                pos_triangulations.append(X)\n",
    "                if len(pos_triangulations)==number:\n",
    "                    return pos_triangulations\n",
    "            break\n",
    "            M.randomize()\n",
    "    return pos_triangulations\n",
    "\n",
    "def better_volume(M,index=100,try_hard=False):\n",
    "    '''Computes the verified volume. Returns 0 if SnapPy could not do it.'''\n",
    "    count=0\n",
    "    while count<index:\n",
    "        try:\n",
    "            return M.volume(verified=True)\n",
    "        except:\n",
    "            M.randomize()\n",
    "            count=count+1\n",
    "    if try_hard==True:\n",
    "        pos_triang=find_positive_triangulations(M,number=1,tries=index)\n",
    "        for X in pos_triang:\n",
    "            vol=better_volume(X,index)\n",
    "            if vol!=0:\n",
    "                return vol\n",
    "    return 0\n",
    "\n",
    "def change_notation(dt_code):\n",
    "    \"\"\"\n",
    "    Changes Dowker-Thistlewait notation from alphabetical to numerical\n",
    "    Input:\n",
    "        dt_code (string): alphabetical DT notation\n",
    "    Return:\n",
    "        (string): numerical DT notation\n",
    "    \"\"\"\n",
    "    alpha = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "    Alpha = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "    result = []\n",
    "    for letter in dt_code:\n",
    "        if letter in alpha:\n",
    "            result.append(2* (alpha.index(letter) + 1))\n",
    "        elif letter in Alpha:\n",
    "            result.append(-2 * (Alpha.index(letter) + 1))\n",
    "        else:\n",
    "            print(dt_code)\n",
    "    return \"DT: \" + str([tuple(result)])\n",
    "\n",
    "def fill_triangulation(M):\n",
    "    '''\n",
    "    Fills all cusps but one.\n",
    "    '''\n",
    "    if M.num_cusps()==1:\n",
    "        return M\n",
    "    M=M.filled_triangulation([0])\n",
    "    M=fill_triangulation(M)\n",
    "    return M\n",
    "\n",
    "#### This is Dunfield's util.py from his exceptional census\n",
    "\n",
    "####  for a snappy manifold M descibed as a single filling of a cusp (so do filled_triangulation() as needed) \n",
    "####  the command regina_name(M) gives what regina identifies M as\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "This file provides functions for working with Regina (with a little\n",
    "help from SnapPy) to:\n",
    "\n",
    "1. Give a standard name (\"identify\") manifolds, especially Seifert and\n",
    "   graph manifolds.\n",
    "\n",
    "2. Find essential tori.\n",
    "\n",
    "3. Try to compute the JSJ decomposition.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import regina\n",
    "import snappy\n",
    "import re\n",
    "import networkx as nx\n",
    "\n",
    "def appears_hyperbolic(M):\n",
    "    acceptable = ['all tetrahedra positively oriented',\n",
    "                  'contains negatively oriented tetrahedra']\n",
    "    return M.solution_type() in acceptable and M.volume() > 0\n",
    "\n",
    "def children(packet):\n",
    "    child = packet.firstChild()\n",
    "    while child:\n",
    "        yield child\n",
    "        child = child.nextSibling()\n",
    "\n",
    "def to_regina(data):\n",
    "    if hasattr(data, '_to_string'):\n",
    "        data = data._to_string()\n",
    "    if isinstance(data, str):\n",
    "        if data.find('(') > -1:\n",
    "            data = closed_isosigs(data)[0]\n",
    "        return regina.Triangulation3(data)\n",
    "    assert isinstance(data, regina.Triangulation3)\n",
    "    return data\n",
    "\n",
    "def extract_vector(surface):\n",
    "    \"\"\"\n",
    "    Extract the raw vector of the (almost) normal surface in Regina's\n",
    "    NS_STANDARD coordinate system.\n",
    "    \"\"\"\n",
    "    S = surface\n",
    "    T = S.triangulation()\n",
    "    n = T.countTetrahedra()\n",
    "    ans = []\n",
    "    for i in range(n):\n",
    "        for j in range(4):\n",
    "            ans.append(S.triangles(i, j))\n",
    "        for j in range(3):\n",
    "            ans.append(S.quads(i, j))\n",
    "    A = regina.NormalSurface(T, regina.NS_STANDARD, ans)\n",
    "    assert A.sameSurface(S)\n",
    "    return ans\n",
    "\n",
    "def haken_sum(S1, S2):\n",
    "    T = S1.triangulation()\n",
    "    assert S1.locallyCompatible(S2)\n",
    "    v1, v2 = extract_vector(S1), extract_vector(S2)\n",
    "    sum_vec = [x1 + x2 for x1, x2 in zip(v1, v2)]\n",
    "    A = regina.NormalSurface(T, regina.NS_STANDARD, sum_vec)\n",
    "    assert S1.locallyCompatible(A) and S2.locallyCompatible(A)\n",
    "    assert S1.eulerChar() + S2.eulerChar() == A.eulerChar()\n",
    "    return A\n",
    "\n",
    "\n",
    "def census_lookup(regina_tri):\n",
    "    \"\"\"\n",
    "    Should the input triangulation be in Regina's census, return the\n",
    "    name of the manifold, dropping the triangulation number.\n",
    "    \"\"\"\n",
    "    hits = regina.Census.lookup(regina_tri)\n",
    "    hit = hits.first()\n",
    "    if hit is not None:\n",
    "        name = hit.name()\n",
    "        match = re.search('(.*) : #\\d+$', name)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "        else:\n",
    "            return match\n",
    "\n",
    "def standard_lookup(regina_tri):\n",
    "    match = regina.StandardTriangulation.isStandardTriangulation(regina_tri)\n",
    "    if match:\n",
    "        return match.manifold()\n",
    "\n",
    "def closed_isosigs(snappy_manifold, trys=20, max_tets=50):\n",
    "    \"\"\"\n",
    "    Generate a slew of 1-vertex triangulations of a closed manifold\n",
    "    using SnapPy.\n",
    "    \n",
    "    >>> M = snappy.Manifold('m004(1,2)')\n",
    "    >>> len(closed_isosigs(M, trys=5)) > 0\n",
    "    True\n",
    "    \"\"\"\n",
    "    M = snappy.Manifold(snappy_manifold)\n",
    "    assert M.cusp_info('complete?') == [False]\n",
    "    surgery_descriptions = [M.copy()]\n",
    "\n",
    "    try:\n",
    "        for curve in M.dual_curves():\n",
    "            N = M.drill(curve)\n",
    "            N.dehn_fill((1,0), 1)\n",
    "            surgery_descriptions.append(N.filled_triangulation([0]))\n",
    "    except snappy.SnapPeaFatalError:\n",
    "        pass\n",
    "\n",
    "    if len(surgery_descriptions) == 1:\n",
    "        # Try again, but unfill the cusp first to try to find more\n",
    "        # dual curves.\n",
    "        try:\n",
    "            filling = M.cusp_info(0).filling\n",
    "            N = M.copy()\n",
    "            N.dehn_fill((0, 0), 0)\n",
    "            N.randomize()\n",
    "            for curve in N.dual_curves():\n",
    "                D = N.drill(curve)\n",
    "                D.dehn_fill([filling, (1,0)])\n",
    "                surgery_descriptions.append(D.filled_triangulation([0]))\n",
    "        except snappy.SnapPeaFatalError:\n",
    "            pass\n",
    "\n",
    "    ans = set()\n",
    "    for N in surgery_descriptions:\n",
    "        for i in range(trys):\n",
    "            T = N.filled_triangulation()\n",
    "            if T._num_fake_cusps() == 1:\n",
    "                n = T.num_tetrahedra()\n",
    "                if n <= max_tets:\n",
    "                    ans.add((n, T.triangulation_isosig(decorated=False)))\n",
    "            N.randomize()\n",
    "\n",
    "    return [iso for n, iso in sorted(ans)]\n",
    "\n",
    "def best_match(matches):\n",
    "    \"\"\"\n",
    "    Prioritize the most concise description that Regina provides to\n",
    "    try to avoid things like the Seifert fibered space of a node being\n",
    "    a solid torus or having several nodes that can be condensed into a\n",
    "    single Seifert fibered piece.\n",
    "    \"\"\"\n",
    "    \n",
    "    def score(m):\n",
    "        if isinstance(m, regina.SFSpace):\n",
    "            s = 0\n",
    "        elif isinstance(m, regina.GraphLoop):\n",
    "            s = 1\n",
    "        elif isinstance(m, regina.GraphPair):\n",
    "            s = 2\n",
    "        elif isinstance(m, regina.GraphTriple):\n",
    "            s = 3\n",
    "        elif m is None:\n",
    "            s = 10000\n",
    "        else:\n",
    "            s = 4\n",
    "        return (s, str(m))\n",
    "    return min(matches, key=score)\n",
    "\n",
    "def identify_with_torus_boundary(regina_tri):\n",
    "    \"\"\"\n",
    "    Use the combined power of Regina and SnapPy to try to give a name\n",
    "    to the input manifold.\n",
    "    \"\"\"\n",
    "    \n",
    "    kind, name = None, None\n",
    "    \n",
    "    P = regina_tri.clone()\n",
    "    P.finiteToIdeal()\n",
    "    P.intelligentSimplify()\n",
    "    M = snappy.Manifold(P.isoSig())\n",
    "    M.simplify()\n",
    "    if appears_hyperbolic(M):\n",
    "        for i in range(100):\n",
    "            if M.solution_type() == 'all tetrahedra positively oriented':\n",
    "                break\n",
    "            M.randomize()\n",
    "        \n",
    "        if not M.verify_hyperbolicity(bits_prec=100):\n",
    "            raise RuntimeError('Cannot prove hyperbolicity for ' +\n",
    "                               M.triangulation_isosig())\n",
    "        kind = 'hyperbolic'\n",
    "        ids = M.identify()\n",
    "        if ids:\n",
    "            name = ids[0].name()\n",
    "    else:\n",
    "        match = standard_lookup(regina_tri)\n",
    "        if match is None:\n",
    "            Q = P.clone()\n",
    "            Q.idealToFinite()\n",
    "            Q.intelligentSimplify()\n",
    "            match = standard_lookup(Q)\n",
    "        if match is not None:\n",
    "            kind = match.__class__.__name__\n",
    "            name = str(match)\n",
    "        else:\n",
    "            name = P.isoSig()\n",
    "    return kind, name\n",
    "            \n",
    "    \n",
    "    \n",
    "\n",
    "def is_toroidal(regina_tri):\n",
    "    \"\"\"\n",
    "    Checks for essential tori and returns the pieces of the\n",
    "    associated partial JSJ decomposition.\n",
    "    \n",
    "    >>> T = to_regina('hLALAkbccfefgglpkusufk')  # m004(4,1)\n",
    "    >>> is_toroidal(T)[0]\n",
    "    True\n",
    "    >>> T = to_regina('hvLAQkcdfegfggjwajpmpw')  # m004(0,1)\n",
    "    >>> is_toroidal(T)[0]\n",
    "    True\n",
    "    >>> T = to_regina('nLLLLMLPQkcdgfihjlmmlkmlhshnrvaqtpsfnf')  # 5_2(10,1)\n",
    "    >>> T.isHaken()\n",
    "    True\n",
    "    >>> is_toroidal(T)[0]\n",
    "    False\n",
    "\n",
    "    Note: currently checks all fundamental normal tori; possibly\n",
    "    the theory lets one just check *vertex* normal tori.\n",
    "    \"\"\"\n",
    "    T = regina_tri\n",
    "    assert T.isZeroEfficient()\n",
    "    surfaces = regina.NNormalSurfaceList.enumerate(T,\n",
    "                          regina.NS_QUAD, regina.NS_FUNDAMENTAL)\n",
    "    for i in range(surfaces.size()):\n",
    "        S = surfaces.surface(i)\n",
    "        if S.eulerChar() == 0:\n",
    "            if not S.isOrientable():\n",
    "                S = S.doubleSurface()\n",
    "            assert S.isOrientable()\n",
    "            X = S.cutAlong()\n",
    "            X.intelligentSimplify()\n",
    "            X.splitIntoComponents()\n",
    "            pieces = list(children(X))\n",
    "            if all(not C.hasCompressingDisc() for C in pieces):\n",
    "                ids = [identify_with_torus_boundary(C) for C in pieces]\n",
    "                return (True, sorted(ids))\n",
    "                \n",
    "    return (False, None)\n",
    "\n",
    "\n",
    "def decompose_along_tori(regina_tri):\n",
    "    \"\"\"\n",
    "    First, finds all essential normal tori in the manifold associated\n",
    "    with fundamental normal surfaces.  Then takes a maximal disjoint\n",
    "    collection of these tori, namely the one with the fewest tori\n",
    "    involved, and cuts the manifold open along it.  It tries to\n",
    "    identify the pieces, removing any (torus x I) components. \n",
    "\n",
    "    Returns: (has essential torus, list of pieces)\n",
    "\n",
    "    Note: This may fail to be the true JSJ decomposition because there\n",
    "    could be (torus x I)'s in the list of pieces and it might well be\n",
    "    possible to amalgamate some of the pieces into a single SFS.\n",
    "    \"\"\"\n",
    "    \n",
    "    T = regina_tri\n",
    "    assert T.isZeroEfficient()\n",
    "    essential_tori = []\n",
    "    surfaces = regina.NNormalSurfaceList.enumerate(T,\n",
    "                          regina.NS_QUAD, regina.NS_FUNDAMENTAL)\n",
    "    for i in range(surfaces.size()):\n",
    "        S = surfaces.surface(i)\n",
    "        if S.eulerChar() == 0:\n",
    "            if not S.isOrientable():\n",
    "                S = S.doubleSurface()\n",
    "            assert S.isOrientable()\n",
    "            X = S.cutAlong()\n",
    "            X.intelligentSimplify()\n",
    "            X.splitIntoComponents()\n",
    "            pieces = list(children(X))\n",
    "            if all(not C.hasCompressingDisc() for C in pieces):\n",
    "                essential_tori.append(S)\n",
    "\n",
    "    if len(essential_tori) == 0:\n",
    "        return False, None\n",
    "    \n",
    "    D = nx.Graph()\n",
    "    for a, A in enumerate(essential_tori):\n",
    "        for b, B in enumerate(essential_tori):\n",
    "            if a < b:\n",
    "                if A.disjoint(B):\n",
    "                    D.add_edge(a, b)\n",
    "\n",
    "    cliques = list(nx.find_cliques(D))\n",
    "    if len(cliques) == 0:\n",
    "        clique = [0]\n",
    "    else:\n",
    "        clique = min(cliques, key=len)\n",
    "    clique = [essential_tori[c] for c in clique]\n",
    "    A = clique[0]\n",
    "    for B in clique[1:]:\n",
    "        A = haken_sum(A, B)\n",
    "\n",
    "    X = A.cutAlong()\n",
    "    X.intelligentSimplify()\n",
    "    X.splitIntoComponents()\n",
    "    ids = [identify_with_torus_boundary(C) for C in list(children(X))]\n",
    "    # Remove products\n",
    "    ids = [i for i in ids if i[1] not in ('SFS [A: (1,1)]', 'A x S1')]\n",
    "    return (True, sorted(ids))\n",
    "\n",
    "def regina_name(closed_snappy_manifold, trys=100):\n",
    "    \"\"\"\n",
    "    >>> regina_name('m004(1,0)')\n",
    "    'S3'\n",
    "    >>> regina_name('s006(-2, 1)')\n",
    "    'SFS [A: (5,1)] / [ 0,-1 | -1,0 ]'\n",
    "    >>> regina_name('m010(-1, 1)')\n",
    "    'L(3,1) # RP3'\n",
    "    >>> regina_name('m022(-1,1)')\n",
    "    'SFS [S2: (3,2) (3,2) (4,-3)]'\n",
    "    >>> regina_name('v0004(0, 1)')\n",
    "    'SFS [S2: (2,1) (4,1) (15,-13)]'\n",
    "    >>> regina_name('m305(1, 0)')\n",
    "    'L(3,1) # RP3'\n",
    "    \"\"\"\n",
    "    M = snappy.Manifold(closed_snappy_manifold)\n",
    "    isosigs = closed_isosigs(M, trys=trys, max_tets=25)\n",
    "    if len(isosigs) == 0:\n",
    "        return\n",
    "    T = to_regina(isosigs[0])\n",
    "    if T.isIrreducible():\n",
    "        if T.countTetrahedra() <= 11:\n",
    "            for i in range(3):\n",
    "                T.simplifyExhaustive(i)\n",
    "                name = census_lookup(T)\n",
    "                if name is not None:\n",
    "                    return name\n",
    "            \n",
    "        matches = [standard_lookup(to_regina(iso)) for iso in isosigs]\n",
    "        match = best_match(matches)\n",
    "        if match is not None:\n",
    "            return str(match)\n",
    "    else:\n",
    "        T.connectedSumDecomposition()\n",
    "        pieces = [regina_name(P) for P in children(T)]\n",
    "        if None not in pieces:\n",
    "            return ' # '.join(sorted(pieces))\n",
    "        \n",
    "def recognize_mfd(knot):\n",
    "    \"\"\"\n",
    "    Uses regina and snappy to recognize the name of its 0-filling.\n",
    "    \"\"\"\n",
    "    K=snappy.Manifold(knot)\n",
    "    K_reg=regina_name(K)\n",
    "    if K_reg is not None:\n",
    "        return K_reg  \n",
    "    else:\n",
    "        try:\n",
    "            K_reg=decompose_along_tori(to_regina(closed_isosigs(K)[0]))\n",
    "        except TypeError:\n",
    "            K_reg=None\n",
    "        if K_reg is not None and K_reg[0]==True:\n",
    "            return 'JSJ'+str(K_reg[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "connected_sums=['3_1_plus_3_1','3_1_plus_4_1','3_1_plus_5_1','3_1_plus_5_2','3_1_plus_6_1','3_1_plus_6_2',\n",
    "                '3_1_plus_6_3','4_1_plus_4_1','4_1_plus_5_1','4_1_plus_5_2','3_1_plus_3_1_plus_3_1']\n",
    "\n",
    "possible_same_0_surgeries=[] \n",
    "for name in connected_sums:\n",
    "    listname=[]\n",
    "    try:\n",
    "        with open(name+'.csv', 'r') as file:\n",
    "            reader = csv.reader(file)\n",
    "            for row in reader:\n",
    "                listname.append(row)\n",
    "            listname=listname[1:]\n",
    "            low_cros=[]\n",
    "            high_cros=[]\n",
    "            for x in listname:\n",
    "                if int(x[1])<16:\n",
    "                    low_cros.append(x)\n",
    "                else:\n",
    "                    high_cros.append(x)\n",
    "            listname=[]\n",
    "            listname.append(low_cros)\n",
    "            listname.append(high_cros)\n",
    "            possible_same_0_surgeries.append(listname)\n",
    "    except FileNotFoundError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(possible_same_0_surgeries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible equal surgeries: [[['3_1_plus_3_1', '6', '']], [['16nh_0000011', '16', 'gNMLKJpIOFEDCBHa'], ['18ns_59', '18', 'hMeKgOcrJQDnBpFlIa'], ['18nh_00000014', '18', 'hPONMLKrJQGFEDCBIa'], ['18nh_00000312', '18', 'eFjGlKIqDnoAPcbRhM'], ['18nh_00000313', '18', 'cFkIgBoLmPaNqReJDh'], ['19nh_000000425', '19', 'kEhpSnIcMQaOGrJdLfB'], ['19nh_000000424', '19', 'jfpSnhLbOrMGQcIeKaD'], ['19nh_000001540', '19', 'ePlQsIOFnArdbhmGCkj']]]\n",
      "Possible equal surgeries: [[['3_1_plus_4_1', '7', '']], []]\n",
      "Possible equal surgeries: [[['3_1_plus_5_1', '8', '']], []]\n",
      "Possible equal surgeries: [[['3_1_plus_5_2', '8', '']], []]\n",
      "Possible equal surgeries: [[['3_1_plus_6_1', '9', '']], []]\n",
      "Possible equal surgeries: [[['3_1_plus_6_2', '9', '']], []]\n",
      "Possible equal surgeries: [[['3_1_plus_6_3', '9', '']], []]\n",
      "Possible equal surgeries: [[['4_1_plus_4_1', '8', '']], []]\n",
      "Possible equal surgeries: [[['4_1_plus_5_1', '9', '']], []]\n",
      "Possible equal surgeries: [[['4_1_plus_5_2', '9', '']], []]\n",
      "Possible equal surgeries: [[['3_1_plus_3_1_plus_3_1', '9', '']], []]\n",
      "Time taken: 1.9242133106788 hours \n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "possible_same_0_surgeries_both_prop_non_hyp=[]\n",
    "\n",
    "for x in possible_same_0_surgeries:\n",
    "    unclear=[]\n",
    "    for [knot,cros,DT] in x[1]:\n",
    "        K=snappy.Link(change_notation(DT)).exterior()\n",
    "        K.dehn_fill((0,1))\n",
    "        vol=better_volume(K)\n",
    "        if vol==0:\n",
    "            unclear.append([knot,cros,DT])\n",
    "    possible_same_0_surgeries_both_prop_non_hyp.append([x[0],unclear]) \n",
    "    print('Possible equal surgeries:',[x[0],unclear])\n",
    "print('Time taken: %s hours ' % ((time.time() - start_time)/3600))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We work a bit harder with the remaining examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['3_1_plus_3_1', '6', '']]\n",
      "16nh_0000011 0\n",
      "18ns_59 0\n",
      "18nh_00000014 0\n",
      "18nh_00000312 0\n",
      "18nh_00000313 0\n",
      "19nh_000000425 0\n",
      "19nh_000000424 0\n",
      "19nh_000001540 11.0645862261?\n",
      "----------------\n",
      "[['3_1_plus_4_1', '7', '']]\n",
      "----------------\n",
      "[['3_1_plus_5_1', '8', '']]\n",
      "----------------\n",
      "[['3_1_plus_5_2', '8', '']]\n",
      "----------------\n",
      "[['3_1_plus_6_1', '9', '']]\n",
      "----------------\n",
      "[['3_1_plus_6_2', '9', '']]\n",
      "----------------\n",
      "[['3_1_plus_6_3', '9', '']]\n",
      "----------------\n",
      "[['4_1_plus_4_1', '8', '']]\n",
      "----------------\n",
      "[['4_1_plus_5_1', '9', '']]\n",
      "----------------\n",
      "[['4_1_plus_5_2', '9', '']]\n",
      "----------------\n",
      "[['3_1_plus_3_1_plus_3_1', '9', '']]\n",
      "----------------\n",
      "Time taken: 0.8123347361882528 minutes \n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "still_unclear=[]\n",
    "for x in possible_same_0_surgeries_both_prop_non_hyp:\n",
    "    print(x[0])\n",
    "    unclear=[]\n",
    "    for [knot,cros,DT] in x[1]:\n",
    "        K=snappy.Link(change_notation(DT)).exterior()\n",
    "        K.dehn_fill((0,1))\n",
    "        vol=better_volume(K,try_hard=True)\n",
    "        print(knot,vol)\n",
    "        if vol==0:\n",
    "            unclear.append([knot,cros,DT])\n",
    "    if len(unclear)>0:\n",
    "        still_unclear.append([x[0],unclear])\n",
    "    print('----------------')\n",
    "print('Time taken: %s minutes ' % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining 0-fillings we expect to be non-hyperbolic. We try to verify that by using the regina code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[['3_1_plus_3_1', '6', '']],\n",
       "  [['16nh_0000011', '16', 'gNMLKJpIOFEDCBHa'],\n",
       "   ['18ns_59', '18', 'hMeKgOcrJQDnBpFlIa'],\n",
       "   ['18nh_00000014', '18', 'hPONMLKrJQGFEDCBIa'],\n",
       "   ['18nh_00000312', '18', 'eFjGlKIqDnoAPcbRhM'],\n",
       "   ['18nh_00000313', '18', 'cFkIgBoLmPaNqReJDh'],\n",
       "   ['19nh_000000425', '19', 'kEhpSnIcMQaOGrJdLfB'],\n",
       "   ['19nh_000000424', '19', 'jfpSnhLbOrMGQcIeKaD']]]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "still_unclear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['3_1_plus_3_1', '6', '']]\n",
      "16nh_0000011 SFS [D: (2,1) (2,1)] U/m SFS [D: (3,1) (3,2)], m = [ -4,5 | -3,4 ]\n",
      "18ns_59 SFS [D: (2,1) (3,1)] U/m Non-or, g=1 + 2 punctures/n2 x~ S1 U/n SFS [D: (3,1) (3,2)], m = [ 1,-1 | 0,1 ], n = [ 2,1 | 1,1 ]\n",
      "18nh_00000014 SFS [D: (2,1) (2,1)] U/m SFS [D: (3,1) (3,2)], m = [ -5,6 | -4,5 ]\n",
      "18nh_00000312 JSJ[('SFSpace', 'SFS [D: (2,1) (2,-1)]'), ('hyperbolic', 's783')]\n",
      "18nh_00000313 JSJ[('SFSpace', 'SFS [D: (2,1) (2,-1)]'), ('hyperbolic', 's783')]\n",
      "19nh_000000425 JSJ[('SFSpace', 'SFS [D: (2,1) (2,-1)]'), ('hyperbolic', 's783')]\n",
      "19nh_000000424 JSJ[('SFSpace', 'SFS [D: (2,1) (2,-1)]'), ('hyperbolic', 's783')]\n",
      "----------------\n",
      "Time taken: 3.361183567841848 minutes \n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for x in still_unclear:\n",
    "    print(x[0])\n",
    "    for [knot,cros,DT] in x[1]:\n",
    "        K=snappy.Link(change_notation(DT)).exterior()\n",
    "        K.dehn_fill((0,1))\n",
    "        rec=recognize_mfd(K)\n",
    "        print(knot,recognize_mfd(K))\n",
    "    print('----------------')\n",
    "print('Time taken: %s minutes ' % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So all these manifolds are really JSJ manifolds. But there pieces are not knot complemenets and thus they cannot be homeomorphic to the 0-surgery of a connected sum. This proves the result."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 9.0",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
