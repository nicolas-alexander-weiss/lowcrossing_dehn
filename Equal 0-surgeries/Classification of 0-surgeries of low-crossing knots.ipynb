{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we classify the 0-surgeries of all prime knots with at most 15 crossings, i.e. we compute their volumes if they are hyperbolic or determine a regina name if they are not hyperbolic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snappy\n",
    "import csv\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_positive(manifold):\n",
    "    '''\n",
    "    Checks if the solution type of a triangulation is positive.\n",
    "    '''\n",
    "    return manifold.solution_type() == 'all tetrahedra positively oriented'\n",
    "\n",
    "def find_positive_triangulations(manifold,number=1,tries=100):\n",
    "    '''\n",
    "    Searches for one triangulation with a positive solution type.\n",
    "    (Or if number is set to a different value also for different such triangulations.)\n",
    "    '''\n",
    "    M = manifold.copy()\n",
    "    pos_triangulations=[]\n",
    "    for i in range(tries):\n",
    "        if all_positive(M):\n",
    "            pos_triangulations.append(M)\n",
    "            if len(pos_triangulations)==number:\n",
    "                return pos_triangulations\n",
    "            break\n",
    "        M.randomize()\n",
    "    for d in M.dual_curves(max_segments=500):\n",
    "        X = M.drill(d)\n",
    "        X = X.filled_triangulation()\n",
    "        X.dehn_fill((1,0),-1)\n",
    "        for i in range(tries):\n",
    "            if all_positive(X):\n",
    "                pos_triangulations.append(X)\n",
    "                if len(pos_triangulations)==number:\n",
    "                    return pos_triangulations\n",
    "                break\n",
    "            X.randomize()\n",
    "\n",
    "    # In the closed case, here is another trick.\n",
    "    if all(not c for c in M.cusp_info('is_complete')):\n",
    "        for i in range(tries):\n",
    "            # Drills out a random edge\n",
    "            X = M.__class__(M.filled_triangulation())\n",
    "            if all_positive(X):\n",
    "                pos_triangulations.append(X)\n",
    "                if len(pos_triangulations)==number:\n",
    "                    return pos_triangulations\n",
    "            break\n",
    "            M.randomize()\n",
    "    return pos_triangulations\n",
    "\n",
    "def better_volume(M,index=100,try_hard=False):\n",
    "    '''Computes the verified volume. Returns 0 if SnapPy could not do it.'''\n",
    "    count=0\n",
    "    while count<index:\n",
    "        try:\n",
    "            return M.volume(verified=True)\n",
    "        except:\n",
    "            M.randomize()\n",
    "            count=count+1\n",
    "    if try_hard==True:\n",
    "        pos_triang=find_positive_triangulations(M,number=1,tries=index)\n",
    "        for X in pos_triang:\n",
    "            vol=better_volume(X,index)\n",
    "            if vol!=0:\n",
    "                return vol\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We could NOT compute the volume of: K3a1(0,1)\n",
      "We could NOT compute the volume of: K4a1(0,1)\n",
      "We could NOT compute the volume of: K5a1(0,1)\n",
      "We could NOT compute the volume of: K5a2(0,1)\n",
      "We could NOT compute the volume of: K6a3(0,1)\n",
      "We could NOT compute the volume of: K7a4(0,1)\n",
      "We could NOT compute the volume of: K7a6(0,1)\n",
      "We could NOT compute the volume of: K7a7(0,1)\n",
      "We could NOT compute the volume of: K8a11(0,1)\n",
      "We could NOT compute the volume of: K8a18(0,1)\n",
      "We could NOT compute the volume of: K8n1(0,1)\n",
      "We could NOT compute the volume of: K8n3(0,1)\n",
      "We could NOT compute the volume of: K9a27(0,1)\n",
      "We could NOT compute the volume of: K9a36(0,1)\n",
      "We could NOT compute the volume of: K9a40(0,1)\n",
      "We could NOT compute the volume of: K9a41(0,1)\n",
      "We could NOT compute the volume of: K9n5(0,1)\n",
      "We could NOT compute the volume of: K10a75(0,1)\n",
      "We could NOT compute the volume of: K10a117(0,1)\n",
      "We could NOT compute the volume of: K10n13(0,1)\n",
      "We could NOT compute the volume of: K10n21(0,1)\n",
      "We could NOT compute the volume of: K10n29(0,1)\n",
      "We could NOT compute the volume of: K11a247(0,1)\n",
      "We could NOT compute the volume of: K11a343(0,1)\n",
      "We could NOT compute the volume of: K11a362(0,1)\n",
      "We could NOT compute the volume of: K11a363(0,1)\n",
      "We could NOT compute the volume of: K11a367(0,1)\n",
      "We could NOT compute the volume of: K11n139(0,1)\n",
      "We could NOT compute the volume of: K11n141(0,1)\n",
      "We have saved the data. Number of knots checked: 1000\n",
      "We could NOT compute the volume of: K12a803(0,1)\n",
      "We could NOT compute the volume of: K12a1166(0,1)\n",
      "We have saved the data. Number of knots checked: 2000\n",
      "We could NOT compute the volume of: K12a1287(0,1)\n",
      "We could NOT compute the volume of: K12n121(0,1)\n",
      "We could NOT compute the volume of: K12n309(0,1)\n",
      "We could NOT compute the volume of: K12n582(0,1)\n",
      "We could NOT compute the volume of: K12n721(0,1)\n",
      "We have saved the data. Number of knots checked: 3000\n",
      "We have saved the data. Number of knots checked: 4000\n",
      "We have saved the data. Number of knots checked: 5000\n",
      "We have saved the data. Number of knots checked: 6000\n",
      "We could NOT compute the volume of: K13a3143(0,1)\n",
      "We have saved the data. Number of knots checked: 7000\n",
      "We could NOT compute the volume of: K13a4573(0,1)\n",
      "We could NOT compute the volume of: K13a4843(0,1)\n",
      "We could NOT compute the volume of: K13a4856(0,1)\n",
      "We could NOT compute the volume of: K13a4873(0,1)\n",
      "We could NOT compute the volume of: K13a4878(0,1)\n",
      "We have saved the data. Number of knots checked: 8000\n",
      "We could NOT compute the volume of: K13n469(0,1)\n",
      "We could NOT compute the volume of: K13n1021(0,1)\n",
      "We have saved the data. Number of knots checked: 9000\n",
      "We have saved the data. Number of knots checked: 10000\n",
      "We have saved the data. Number of knots checked: 11000\n",
      "We could NOT compute the volume of: K13n3521(0,1)\n",
      "We could NOT compute the volume of: K13n3523(0,1)\n",
      "We could NOT compute the volume of: K13n3594(0,1)\n",
      "We could NOT compute the volume of: K13n3596(0,1)\n",
      "We could NOT compute the volume of: K13n3663(0,1)\n",
      "We have saved the data. Number of knots checked: 12000\n",
      "We could NOT compute the volume of: K13n4587(0,1)\n",
      "We could NOT compute the volume of: K13n4639(0,1)\n",
      "We have saved the data. Number of knots checked: 13000\n",
      "We have saved the data. Number of knots checked: 14000\n",
      "We have saved the data. Number of knots checked: 15000\n",
      "We have saved the data. Number of knots checked: 16000\n",
      "We have saved the data. Number of knots checked: 17000\n",
      "We have saved the data. Number of knots checked: 18000\n",
      "We have saved the data. Number of knots checked: 19000\n",
      "We have saved the data. Number of knots checked: 20000\n",
      "We have saved the data. Number of knots checked: 21000\n",
      "We have saved the data. Number of knots checked: 22000\n",
      "We have saved the data. Number of knots checked: 23000\n",
      "We have saved the data. Number of knots checked: 24000\n",
      "We have saved the data. Number of knots checked: 25000\n",
      "We could NOT compute the volume of: K14a12741(0,1)\n",
      "We have saved the data. Number of knots checked: 26000\n",
      "We have saved the data. Number of knots checked: 27000\n",
      "We have saved the data. Number of knots checked: 28000\n",
      "We have saved the data. Number of knots checked: 29000\n",
      "We have saved the data. Number of knots checked: 30000\n",
      "We could NOT compute the volume of: K14a17730(0,1)\n",
      "We have saved the data. Number of knots checked: 31000\n",
      "We have saved the data. Number of knots checked: 32000\n",
      "We could NOT compute the volume of: K14a19429(0,1)\n",
      "We have saved the data. Number of knots checked: 33000\n",
      "We have saved the data. Number of knots checked: 34000\n",
      "We have saved the data. Number of knots checked: 35000\n",
      "We have saved the data. Number of knots checked: 36000\n",
      "We could NOT compute the volume of: K14n3611(0,1)\n",
      "We have saved the data. Number of knots checked: 37000\n",
      "We have saved the data. Number of knots checked: 38000\n",
      "We have saved the data. Number of knots checked: 39000\n",
      "We have saved the data. Number of knots checked: 40000\n",
      "We have saved the data. Number of knots checked: 41000\n",
      "We have saved the data. Number of knots checked: 42000\n",
      "We have saved the data. Number of knots checked: 43000\n",
      "We have saved the data. Number of knots checked: 44000\n",
      "We have saved the data. Number of knots checked: 45000\n",
      "We have saved the data. Number of knots checked: 46000\n",
      "We could NOT compute the volume of: K14n14254(0,1)\n",
      "We have saved the data. Number of knots checked: 47000\n",
      "We have saved the data. Number of knots checked: 48000\n",
      "We have saved the data. Number of knots checked: 49000\n",
      "We have saved the data. Number of knots checked: 50000\n",
      "We could NOT compute the volume of: K14n18212(0,1)\n",
      "We have saved the data. Number of knots checked: 51000\n",
      "We could NOT compute the volume of: K14n19265(0,1)\n",
      "We have saved the data. Number of knots checked: 52000\n",
      "We have saved the data. Number of knots checked: 53000\n",
      "We have saved the data. Number of knots checked: 54000\n",
      "We could NOT compute the volume of: K14n21881(0,1)\n",
      "We could NOT compute the volume of: K14n21882(0,1)\n",
      "We could NOT compute the volume of: K14n22073(0,1)\n",
      "We could NOT compute the volume of: K14n22180(0,1)\n",
      "We could NOT compute the volume of: K14n22185(0,1)\n",
      "We have saved the data. Number of knots checked: 55000\n",
      "We could NOT compute the volume of: K14n22589(0,1)\n",
      "We have saved the data. Number of knots checked: 56000\n",
      "We have saved the data. Number of knots checked: 57000\n",
      "We could NOT compute the volume of: K14n24553(0,1)\n",
      "We have saved the data. Number of knots checked: 58000\n",
      "We could NOT compute the volume of: K14n26039(0,1)\n",
      "We have saved the data. Number of knots checked: 59000\n",
      "We have saved the data. Number of knots checked: 60000\n",
      "We have saved the data. Number of knots checked: 61000\n",
      "We have saved the data. Number of knots checked: 62000\n",
      "We have saved the data. Number of knots checked: 63000\n",
      "We have saved the data. Number of knots checked: 64000\n",
      "We have saved the data. Number of knots checked: 65000\n",
      "We have saved the data. Number of knots checked: 66000\n",
      "We have saved the data. Number of knots checked: 67000\n",
      "We have saved the data. Number of knots checked: 68000\n",
      "We have saved the data. Number of knots checked: 69000\n",
      "We have saved the data. Number of knots checked: 70000\n",
      "We have saved the data. Number of knots checked: 71000\n",
      "We have saved the data. Number of knots checked: 72000\n",
      "We have saved the data. Number of knots checked: 73000\n",
      "We have saved the data. Number of knots checked: 74000\n",
      "We have saved the data. Number of knots checked: 75000\n",
      "We have saved the data. Number of knots checked: 76000\n",
      "We have saved the data. Number of knots checked: 77000\n",
      "We have saved the data. Number of knots checked: 78000\n",
      "We have saved the data. Number of knots checked: 79000\n",
      "We have saved the data. Number of knots checked: 80000\n",
      "We have saved the data. Number of knots checked: 81000\n",
      "We have saved the data. Number of knots checked: 82000\n",
      "We have saved the data. Number of knots checked: 83000\n",
      "We have saved the data. Number of knots checked: 84000\n",
      "We have saved the data. Number of knots checked: 85000\n",
      "We have saved the data. Number of knots checked: 86000\n",
      "We have saved the data. Number of knots checked: 87000\n",
      "We have saved the data. Number of knots checked: 88000\n",
      "We have saved the data. Number of knots checked: 89000\n",
      "We have saved the data. Number of knots checked: 90000\n",
      "We have saved the data. Number of knots checked: 91000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have saved the data. Number of knots checked: 92000\n",
      "We have saved the data. Number of knots checked: 93000\n",
      "We have saved the data. Number of knots checked: 94000\n",
      "We have saved the data. Number of knots checked: 95000\n",
      "We have saved the data. Number of knots checked: 96000\n",
      "We have saved the data. Number of knots checked: 97000\n",
      "We have saved the data. Number of knots checked: 98000\n",
      "We have saved the data. Number of knots checked: 99000\n",
      "We have saved the data. Number of knots checked: 100000\n",
      "We have saved the data. Number of knots checked: 101000\n",
      "We have saved the data. Number of knots checked: 102000\n",
      "We have saved the data. Number of knots checked: 103000\n",
      "We have saved the data. Number of knots checked: 104000\n",
      "We have saved the data. Number of knots checked: 105000\n",
      "We have saved the data. Number of knots checked: 106000\n",
      "We have saved the data. Number of knots checked: 107000\n",
      "We have saved the data. Number of knots checked: 108000\n",
      "We have saved the data. Number of knots checked: 109000\n",
      "We have saved the data. Number of knots checked: 110000\n",
      "We have saved the data. Number of knots checked: 111000\n",
      "We have saved the data. Number of knots checked: 112000\n",
      "We have saved the data. Number of knots checked: 113000\n",
      "We have saved the data. Number of knots checked: 114000\n",
      "We could NOT compute the volume of: K15a54894(0,1)\n",
      "We have saved the data. Number of knots checked: 115000\n",
      "We have saved the data. Number of knots checked: 116000\n",
      "We have saved the data. Number of knots checked: 117000\n",
      "We have saved the data. Number of knots checked: 118000\n",
      "We have saved the data. Number of knots checked: 119000\n",
      "We have saved the data. Number of knots checked: 120000\n",
      "We have saved the data. Number of knots checked: 121000\n",
      "We have saved the data. Number of knots checked: 122000\n",
      "We have saved the data. Number of knots checked: 123000\n",
      "We have saved the data. Number of knots checked: 124000\n",
      "We have saved the data. Number of knots checked: 125000\n",
      "We have saved the data. Number of knots checked: 126000\n",
      "We have saved the data. Number of knots checked: 127000\n",
      "We have saved the data. Number of knots checked: 128000\n",
      "We have saved the data. Number of knots checked: 129000\n",
      "We have saved the data. Number of knots checked: 130000\n",
      "We have saved the data. Number of knots checked: 131000\n",
      "We have saved the data. Number of knots checked: 132000\n",
      "We have saved the data. Number of knots checked: 133000\n",
      "We have saved the data. Number of knots checked: 134000\n",
      "We have saved the data. Number of knots checked: 135000\n",
      "We have saved the data. Number of knots checked: 136000\n",
      "We have saved the data. Number of knots checked: 137000\n",
      "We have saved the data. Number of knots checked: 138000\n",
      "We could NOT compute the volume of: K15a78880(0,1)\n",
      "We have saved the data. Number of knots checked: 139000\n",
      "We have saved the data. Number of knots checked: 140000\n",
      "We have saved the data. Number of knots checked: 141000\n",
      "We have saved the data. Number of knots checked: 142000\n",
      "We have saved the data. Number of knots checked: 143000\n",
      "We have saved the data. Number of knots checked: 144000\n",
      "We could NOT compute the volume of: K15a84844(0,1)\n",
      "We could NOT compute the volume of: K15a84969(0,1)\n",
      "We have saved the data. Number of knots checked: 145000\n",
      "We could NOT compute the volume of: K15a85213(0,1)\n",
      "We could NOT compute the volume of: K15a85234(0,1)\n",
      "We could NOT compute the volume of: K15a85257(0,1)\n",
      "We could NOT compute the volume of: K15a85263(0,1)\n",
      "We have saved the data. Number of knots checked: 146000\n",
      "We have saved the data. Number of knots checked: 147000\n",
      "We have saved the data. Number of knots checked: 148000\n",
      "We have saved the data. Number of knots checked: 149000\n",
      "We have saved the data. Number of knots checked: 150000\n",
      "We have saved the data. Number of knots checked: 151000\n",
      "We have saved the data. Number of knots checked: 152000\n",
      "We have saved the data. Number of knots checked: 153000\n",
      "We have saved the data. Number of knots checked: 154000\n",
      "We have saved the data. Number of knots checked: 155000\n",
      "We have saved the data. Number of knots checked: 156000\n",
      "We have saved the data. Number of knots checked: 157000\n",
      "We have saved the data. Number of knots checked: 158000\n",
      "We have saved the data. Number of knots checked: 159000\n",
      "We have saved the data. Number of knots checked: 160000\n",
      "We have saved the data. Number of knots checked: 161000\n",
      "We have saved the data. Number of knots checked: 162000\n",
      "We have saved the data. Number of knots checked: 163000\n",
      "We have saved the data. Number of knots checked: 164000\n",
      "We could NOT compute the volume of: K15n19499(0,1)\n",
      "We have saved the data. Number of knots checked: 165000\n",
      "We have saved the data. Number of knots checked: 166000\n",
      "We have saved the data. Number of knots checked: 167000\n",
      "We have saved the data. Number of knots checked: 168000\n",
      "We have saved the data. Number of knots checked: 169000\n",
      "We have saved the data. Number of knots checked: 170000\n",
      "We have saved the data. Number of knots checked: 171000\n",
      "We have saved the data. Number of knots checked: 172000\n",
      "We have saved the data. Number of knots checked: 173000\n",
      "We could NOT compute the volume of: K15n27975(0,1)\n",
      "We have saved the data. Number of knots checked: 174000\n",
      "We have saved the data. Number of knots checked: 175000\n",
      "We could NOT compute the volume of: K15n30281(0,1)\n",
      "We have saved the data. Number of knots checked: 176000\n",
      "We have saved the data. Number of knots checked: 177000\n",
      "We have saved the data. Number of knots checked: 178000\n",
      "We have saved the data. Number of knots checked: 179000\n",
      "We have saved the data. Number of knots checked: 180000\n",
      "We have saved the data. Number of knots checked: 181000\n",
      "We have saved the data. Number of knots checked: 182000\n",
      "We have saved the data. Number of knots checked: 183000\n",
      "We have saved the data. Number of knots checked: 184000\n",
      "We have saved the data. Number of knots checked: 185000\n",
      "We could NOT compute the volume of: K15n40211(0,1)\n",
      "We have saved the data. Number of knots checked: 186000\n",
      "We could NOT compute the volume of: K15n41185(0,1)\n",
      "We have saved the data. Number of knots checked: 187000\n",
      "We have saved the data. Number of knots checked: 188000\n",
      "We could NOT compute the volume of: K15n43522(0,1)\n",
      "We have saved the data. Number of knots checked: 189000\n",
      "We have saved the data. Number of knots checked: 190000\n",
      "We have saved the data. Number of knots checked: 191000\n",
      "We have saved the data. Number of knots checked: 192000\n",
      "We have saved the data. Number of knots checked: 193000\n",
      "We have saved the data. Number of knots checked: 194000\n",
      "We could NOT compute the volume of: K15n48968(0,1)\n",
      "We have saved the data. Number of knots checked: 195000\n",
      "We have saved the data. Number of knots checked: 196000\n",
      "We could NOT compute the volume of: K15n51748(0,1)\n",
      "We have saved the data. Number of knots checked: 197000\n",
      "We have saved the data. Number of knots checked: 198000\n",
      "We have saved the data. Number of knots checked: 199000\n",
      "We have saved the data. Number of knots checked: 200000\n",
      "We have saved the data. Number of knots checked: 201000\n",
      "We have saved the data. Number of knots checked: 202000\n",
      "We have saved the data. Number of knots checked: 203000\n",
      "We have saved the data. Number of knots checked: 204000\n",
      "We could NOT compute the volume of: K15n59184(0,1)\n",
      "We have saved the data. Number of knots checked: 205000\n",
      "We have saved the data. Number of knots checked: 206000\n",
      "We have saved the data. Number of knots checked: 207000\n",
      "We have saved the data. Number of knots checked: 208000\n",
      "We have saved the data. Number of knots checked: 209000\n",
      "We have saved the data. Number of knots checked: 210000\n",
      "We have saved the data. Number of knots checked: 211000\n",
      "We have saved the data. Number of knots checked: 212000\n",
      "We have saved the data. Number of knots checked: 213000\n",
      "We have saved the data. Number of knots checked: 214000\n",
      "We have saved the data. Number of knots checked: 215000\n",
      "We have saved the data. Number of knots checked: 216000\n",
      "We have saved the data. Number of knots checked: 217000\n",
      "We could NOT compute the volume of: K15n72303(0,1)\n",
      "We have saved the data. Number of knots checked: 218000\n",
      "We have saved the data. Number of knots checked: 219000\n",
      "We have saved the data. Number of knots checked: 220000\n",
      "We have saved the data. Number of knots checked: 221000\n",
      "We have saved the data. Number of knots checked: 222000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have saved the data. Number of knots checked: 223000\n",
      "We have saved the data. Number of knots checked: 224000\n",
      "We have saved the data. Number of knots checked: 225000\n",
      "We have saved the data. Number of knots checked: 226000\n",
      "We have saved the data. Number of knots checked: 227000\n",
      "We have saved the data. Number of knots checked: 228000\n",
      "We have saved the data. Number of knots checked: 229000\n",
      "We have saved the data. Number of knots checked: 230000\n",
      "We have saved the data. Number of knots checked: 231000\n",
      "We have saved the data. Number of knots checked: 232000\n",
      "We have saved the data. Number of knots checked: 233000\n",
      "We have saved the data. Number of knots checked: 234000\n",
      "We have saved the data. Number of knots checked: 235000\n",
      "We have saved the data. Number of knots checked: 236000\n",
      "We have saved the data. Number of knots checked: 237000\n",
      "We have saved the data. Number of knots checked: 238000\n",
      "We have saved the data. Number of knots checked: 239000\n",
      "We could NOT compute the volume of: K15n94464(0,1)\n",
      "We have saved the data. Number of knots checked: 240000\n",
      "We have saved the data. Number of knots checked: 241000\n",
      "We have saved the data. Number of knots checked: 242000\n",
      "We have saved the data. Number of knots checked: 243000\n",
      "We have saved the data. Number of knots checked: 244000\n",
      "We have saved the data. Number of knots checked: 245000\n",
      "We have saved the data. Number of knots checked: 246000\n",
      "We could NOT compute the volume of: K15n101402(0,1)\n",
      "We have saved the data. Number of knots checked: 247000\n",
      "We have saved the data. Number of knots checked: 248000\n",
      "We have saved the data. Number of knots checked: 249000\n",
      "We have saved the data. Number of knots checked: 250000\n",
      "We have saved the data. Number of knots checked: 251000\n",
      "We have saved the data. Number of knots checked: 252000\n",
      "We have saved the data. Number of knots checked: 253000\n",
      "We have saved the data. Number of knots checked: 254000\n",
      "We have saved the data. Number of knots checked: 255000\n",
      "We have saved the data. Number of knots checked: 256000\n",
      "We have saved the data. Number of knots checked: 257000\n",
      "We could NOT compute the volume of: K15n112477(0,1)\n",
      "We could NOT compute the volume of: K15n112479(0,1)\n",
      "We have saved the data. Number of knots checked: 258000\n",
      "We could NOT compute the volume of: K15n113773(0,1)\n",
      "We could NOT compute the volume of: K15n113775(0,1)\n",
      "We have saved the data. Number of knots checked: 259000\n",
      "We could NOT compute the volume of: K15n113923(0,1)\n",
      "We have saved the data. Number of knots checked: 260000\n",
      "We could NOT compute the volume of: K15n115375(0,1)\n",
      "We could NOT compute the volume of: K15n115646(0,1)\n",
      "We have saved the data. Number of knots checked: 261000\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "volumes=[]\n",
    "unclear_volumes=[]\n",
    "count=0\n",
    "\n",
    "for K in snappy.HTLinkExteriors(knots_vs_links='knots'):\n",
    "    K.dehn_fill((0,1))\n",
    "    vol=better_volume(K,index=10)\n",
    "    if vol==0:\n",
    "        vol=better_volume(K,index=100)\n",
    "    if vol==0:\n",
    "        print('We could NOT compute the volume of:',K)\n",
    "        unclear_volumes.append([K.name()])\n",
    "    if vol!=0:\n",
    "        volumes.append([K.name(),vol])\n",
    "    count=count+1\n",
    "    if count%1000 ==0:   \n",
    "        with open('unclear_volumes.pickle', 'wb') as f:\n",
    "            pickle.dump(unclear_volumes, f)\n",
    "        with open('volumes.pickle', 'wb') as f:\n",
    "            pickle.dump(volumes, f)\n",
    "        print('We have saved the data. Number of knots checked:',count)\n",
    "\n",
    "print('Number of knots where we could compute the volume:',len(volumes))\n",
    "print('Number of knots for which we could NOT compute the volume:',len(unclear_volumes))\n",
    "print('Time taken: %s hours ' % ((time.time() - start_time)/3600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "volumes = pickle.load( open( \"volumes.pickle\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260907"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(volumes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['K15n115800', 21.07774672860?]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volumes[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "K15n115800(0,0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snappy.HTLinkExteriors(knots_vs_links='knots',crossings=15)[201062]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have saved the data. Number of knots checked: 1000\n",
      "We have saved the data. Number of knots checked: 2000\n",
      "We have saved the data. Number of knots checked: 3000\n",
      "We have saved the data. Number of knots checked: 4000\n",
      "We have saved the data. Number of knots checked: 5000\n",
      "We have saved the data. Number of knots checked: 6000\n",
      "We have saved the data. Number of knots checked: 7000\n",
      "We have saved the data. Number of knots checked: 8000\n",
      "We have saved the data. Number of knots checked: 9000\n",
      "We could NOT compute the volume of: K15n124802(0,1)\n",
      "We have saved the data. Number of knots checked: 10000\n",
      "We have saved the data. Number of knots checked: 11000\n",
      "We have saved the data. Number of knots checked: 12000\n",
      "We have saved the data. Number of knots checked: 13000\n",
      "We have saved the data. Number of knots checked: 14000\n",
      "We have saved the data. Number of knots checked: 15000\n",
      "We have saved the data. Number of knots checked: 16000\n",
      "We have saved the data. Number of knots checked: 17000\n",
      "We have saved the data. Number of knots checked: 18000\n",
      "We have saved the data. Number of knots checked: 19000\n",
      "We have saved the data. Number of knots checked: 20000\n",
      "We have saved the data. Number of knots checked: 21000\n",
      "We have saved the data. Number of knots checked: 22000\n",
      "We have saved the data. Number of knots checked: 23000\n",
      "We have saved the data. Number of knots checked: 24000\n",
      "We have saved the data. Number of knots checked: 25000\n",
      "We have saved the data. Number of knots checked: 26000\n",
      "We could NOT compute the volume of: K15n142188(0,1)\n",
      "We have saved the data. Number of knots checked: 27000\n",
      "We have saved the data. Number of knots checked: 28000\n",
      "We have saved the data. Number of knots checked: 29000\n",
      "We have saved the data. Number of knots checked: 30000\n",
      "We have saved the data. Number of knots checked: 31000\n",
      "We have saved the data. Number of knots checked: 32000\n",
      "We have saved the data. Number of knots checked: 33000\n",
      "We have saved the data. Number of knots checked: 34000\n",
      "We have saved the data. Number of knots checked: 35000\n",
      "We have saved the data. Number of knots checked: 36000\n",
      "We have saved the data. Number of knots checked: 37000\n",
      "We could NOT compute the volume of: K15n153789(0,1)\n",
      "We have saved the data. Number of knots checked: 38000\n",
      "We have saved the data. Number of knots checked: 39000\n",
      "We have saved the data. Number of knots checked: 40000\n",
      "We could NOT compute the volume of: K15n156076(0,1)\n",
      "We have saved the data. Number of knots checked: 41000\n",
      "We have saved the data. Number of knots checked: 42000\n",
      "We have saved the data. Number of knots checked: 43000\n",
      "We have saved the data. Number of knots checked: 44000\n",
      "We have saved the data. Number of knots checked: 45000\n",
      "We could NOT compute the volume of: K15n160926(0,1)\n",
      "We have saved the data. Number of knots checked: 46000\n",
      "We have saved the data. Number of knots checked: 47000\n",
      "We have saved the data. Number of knots checked: 48000\n",
      "We could NOT compute the volume of: K15n164338(0,1)\n",
      "We have saved the data. Number of knots checked: 49000\n",
      "We have saved the data. Number of knots checked: 50000\n",
      "We have saved the data. Number of knots checked: 51000\n",
      "We have saved the data. Number of knots checked: 52000\n",
      "Number of knots where we could compute the volume: 52224\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'unclear_volume' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-268e261eca54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of knots where we could compute the volume:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvolumes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of knots for which we could NOT compute the volume:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munclear_volume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Time taken: %s hours '\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mInteger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'unclear_volume' is not defined"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "volumes=[]\n",
    "unclear_volumes=[]\n",
    "count=0\n",
    "\n",
    "for K in snappy.HTLinkExteriors(knots_vs_links='knots',crossings=15)[201063:]:\n",
    "    K.dehn_fill((0,1))\n",
    "    vol=better_volume(K,index=10)\n",
    "    if vol==0:\n",
    "        vol=better_volume(K,index=100)\n",
    "    if vol==0:\n",
    "        print('We could NOT compute the volume of:',K)\n",
    "        unclear_volumes.append([K.name()])\n",
    "    if vol!=0:\n",
    "        volumes.append([K.name(),vol])\n",
    "    count=count+1\n",
    "    if count%1000 ==0:   \n",
    "        with open('unclear_volumes2.pickle', 'wb') as f:\n",
    "            pickle.dump(unclear_volumes, f)\n",
    "        with open('volumes2.pickle', 'wb') as f:\n",
    "            pickle.dump(volumes, f)\n",
    "        print('We have saved the data. Number of knots checked:',count)\n",
    "\n",
    "print('Number of knots where we could compute the volume:',len(volumes))\n",
    "print('Number of knots for which we could NOT compute the volume:',len(unclear_volumes))\n",
    "print('Time taken: %s hours ' % ((time.time() - start_time)/3600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "volumes = pickle.load( open( \"volumes.pickle\", \"rb\" ) )+ pickle.load( open( \"volumes2.pickle\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "unclear_volumes = pickle.load( open( \"unclear_volumes.pickle\", \"rb\" ) )+ pickle.load( open( \"unclear_volumes2.pickle\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312901"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(volumes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unclear_volumes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313230"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(snappy.HTLinkExteriors(knots_vs_links='knots'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(volumes)+len(unclear_volumes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So 230 knots are missing, we identify those and compute the volumes of their 0-fillings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST=[]\n",
    "for K in snappy.HTLinkExteriors(knots_vs_links='knots'):\n",
    "    TEST.append(K.name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313230"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing=list(set(TEST).difference(set([x[0] for x in volumes+unclear_volumes])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "230"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of knots where we could compute the volume: 313131\n",
      "Number of knots for which we could NOT compute the volume: 64\n",
      "Time taken: 0.006966460612085131 hours \n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for x in missing:\n",
    "    K=snappy.Manifold(x)\n",
    "    K.dehn_fill((0,1))\n",
    "    vol=better_volume(K,index=10)\n",
    "    if vol==0:\n",
    "        vol=better_volume(K,index=100)\n",
    "    if vol==0:\n",
    "        print('We could NOT compute the volume of:',K)\n",
    "        unclear_volumes.append([K.name()])\n",
    "    if vol!=0:\n",
    "        volumes.append([K.name(),vol])\n",
    "\n",
    "with open('unclear_volumes_done.pickle', 'wb') as f:\n",
    "    pickle.dump(unclear_volumes, f)\n",
    "with open('volumes_done.pickle', 'wb') as f:\n",
    "    pickle.dump(volumes, f)\n",
    "\n",
    "print('Number of knots where we could compute the volume:',len(volumes))\n",
    "print('Number of knots for which we could NOT compute the volume:',len(unclear_volumes))\n",
    "print('Time taken: %s hours ' % ((time.time() - start_time)/3600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313230"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(volumes)+len(unclear_volumes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313230"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'volumes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-1da84a8e11f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munclear_volumes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'volumes.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvolumes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'volumes' is not defined"
     ]
    }
   ],
   "source": [
    "# We save everything:\n",
    "\n",
    "with open('volumes.pickle', 'wb') as f:\n",
    "    pickle.dump(volumes, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "unclear_volumes = pickle.load( open( \"unclear_volumes_done.pickle\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unclear_volumes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 99 knots where snappy could not compute the volume we use regina to actually show that it is not hyperbolic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:94: DeprecationWarning: invalid escape sequence \\d\n",
      "<>:94: DeprecationWarning: invalid escape sequence \\d\n",
      "<ipython-input-5-7105117b759e>:94: DeprecationWarning: invalid escape sequence \\d\n",
      "  match = re.search('(.*) : #\\d+$', name)\n",
      "/usr/lib/python3.8/inspect.py:520: DeprecationWarning: \n",
      "Importing absolute_igusa_invariants_kohel from here is deprecated. If you need to use it, please import it directly from sage.schemes.hyperelliptic_curves.invariants\n",
      "See https://trac.sagemath.org/28064 for details.\n",
      "  while _is_wrapper(func):\n",
      "/usr/lib/python3.8/inspect.py:520: DeprecationWarning: \n",
      "Importing absolute_igusa_invariants_wamelen from here is deprecated. If you need to use it, please import it directly from sage.schemes.hyperelliptic_curves.invariants\n",
      "See https://trac.sagemath.org/28064 for details.\n",
      "  while _is_wrapper(func):\n",
      "/usr/lib/python3.8/inspect.py:520: DeprecationWarning: this is being removed from the global namespace\n",
      "See https://trac.sagemath.org/25785 for details.\n",
      "  while _is_wrapper(func):\n",
      "/usr/lib/python3.8/inspect.py:520: DeprecationWarning: \n",
      "Importing all_max_clique from here is deprecated. If you need to use it, please import it directly from sage.graphs.cliquer\n",
      "See https://trac.sagemath.org/26200 for details.\n",
      "  while _is_wrapper(func):\n",
      "/usr/lib/python3.8/inspect.py:520: DeprecationWarning: \n",
      "Importing backtrack_all from here is deprecated. If you need to use it, please import it directly from sage.games.sudoku_backtrack\n",
      "See https://trac.sagemath.org/27066 for details.\n",
      "  while _is_wrapper(func):\n",
      "/usr/lib/python3.8/inspect.py:520: DeprecationWarning: \n",
      "Importing berlekamp_massey from here is deprecated. If you need to use it, please import it directly from sage.matrix.berlekamp_massey\n",
      "See https://trac.sagemath.org/27066 for details.\n",
      "  while _is_wrapper(func):\n",
      "/usr/lib/python3.8/inspect.py:520: DeprecationWarning: this is being removed from the global namespace\n",
      "See https://trac.sagemath.org/25785 for details.\n",
      "  while _is_wrapper(func):\n",
      "/usr/lib/python3.8/inspect.py:520: DeprecationWarning: \n",
      "Importing buzzard_tpslopes from here is deprecated. If you need to use it, please import it directly from sage.modular.buzzard\n",
      "See https://trac.sagemath.org/27066 for details.\n",
      "  while _is_wrapper(func):\n",
      "/usr/lib/python3.8/inspect.py:520: DeprecationWarning: \n",
      "Importing clebsch_invariants from here is deprecated. If you need to use it, please import it directly from sage.schemes.hyperelliptic_curves.invariants\n",
      "See https://trac.sagemath.org/28064 for details.\n",
      "  while _is_wrapper(func):\n",
      "/usr/lib/python3.8/inspect.py:520: DeprecationWarning: \n",
      "Importing clique_number from here is deprecated. If you need to use it, please import it directly from sage.graphs.cliquer\n",
      "See https://trac.sagemath.org/26200 for details.\n",
      "  while _is_wrapper(func):\n",
      "/usr/lib/python3.8/inspect.py:520: DeprecationWarning: \n",
      "Importing convergents from here is deprecated. If you need to use it, please import it directly from sage.rings.continued_fraction\n",
      "See https://trac.sagemath.org/27066 for details.\n",
      "  while _is_wrapper(func):\n",
      "/usr/lib/python3.8/inspect.py:511: DeprecationWarning: sage.interacts.debugger is deprecated because it is meant for the deprecated Sage Notebook\n",
      "See https://trac.sagemath.org/27531 for details.\n",
      "  return hasattr(f, '__wrapped__')\n",
      "/usr/lib/python3.8/inspect.py:520: DeprecationWarning: \n",
      "Importing designs_from_XML from here is deprecated. If you need to use it, please import it directly from sage.combinat.designs.ext_rep\n",
      "See https://trac.sagemath.org/27066 for details.\n",
      "  while _is_wrapper(func):\n",
      "/usr/lib/python3.8/inspect.py:520: DeprecationWarning: \n",
      "Importing designs_from_XML_url from here is deprecated. If you need to use it, please import it directly from sage.combinat.designs.ext_rep\n",
      "See https://trac.sagemath.org/27066 for details.\n",
      "  while _is_wrapper(func):\n",
      "/usr/lib/python3.8/inspect.py:520: DeprecationWarning: this is being removed from the global namespace\n",
      "See https://trac.sagemath.org/25785 for details.\n",
      "  while _is_wrapper(func):\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sagenb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7105117b759e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mdoctest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoctest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtestmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.8/doctest.py\u001b[0m in \u001b[0;36mtestmod\u001b[0;34m(m, name, globs, verbose, report, optionflags, extraglobs, raise_on_error, exclude_empty)\u001b[0m\n\u001b[1;32m   1953\u001b[0m         \u001b[0mrunner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDocTestRunner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptionflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptionflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1955\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfinder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextraglobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextraglobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1956\u001b[0m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/doctest.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(self, obj, name, module, globs, extraglobs)\u001b[0m\n\u001b[1;32m    937\u001b[0m         \u001b[0;31m# Recursively explore `obj`, extracting DocTests.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m         \u001b[0mtests\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 939\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtests\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    940\u001b[0m         \u001b[0;31m# Sort the tests by alpha order of names, for consistency in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0;31m# verbose-mode output.  This was a feature of doctest in Pythons\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/doctest.py\u001b[0m in \u001b[0;36m_find\u001b[0;34m(self, tests, obj, name, module, source_lines, globs, seen)\u001b[0m\n\u001b[1;32m    996\u001b[0m                 \u001b[0mvalname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'%s.%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m                 \u001b[0;31m# Recurse to functions & classes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 998\u001b[0;31m                 if ((inspect.isroutine(inspect.unwrap(val))\n\u001b[0m\u001b[1;32m    999\u001b[0m                      or inspect.isclass(val)) and\n\u001b[1;32m   1000\u001b[0m                     self._from_module(module, val)):\n",
      "\u001b[0;32m/usr/lib/python3.8/inspect.py\u001b[0m in \u001b[0;36munwrap\u001b[0;34m(func, stop)\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0mmemo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m     \u001b[0mrecursion_limit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetrecursionlimit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0m_is_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0mid_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/inspect.py\u001b[0m in \u001b[0;36m_is_wrapper\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstop\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_is_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__wrapped__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_is_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/sage/misc/lazy_import.pyx\u001b[0m in \u001b[0;36msage.misc.lazy_import.LazyImport.__getattr__ (build/cythonized/sage/misc/lazy_import.c:3536)\u001b[0;34m()\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \"\"\"\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[0;31m# We need to wrap all the slot methods, as they are not forwarded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/sage/misc/lazy_import.pyx\u001b[0m in \u001b[0;36msage.misc.lazy_import.LazyImport.get_object (build/cythonized/sage/misc/lazy_import.c:2347)\u001b[0;34m()\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlikely\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0mcpdef\u001b[0m \u001b[0m_get_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/sage/misc/lazy_import.pyx\u001b[0m in \u001b[0;36msage.misc.lazy_import.LazyImport._get_object (build/cythonized/sage/misc/lazy_import.c:2586)\u001b[0;34m()\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_at_startup\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstartup_guard\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Option ``at_startup=True`` for lazy import {0} not needed anymore'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deprecation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sagenb'"
     ]
    }
   ],
   "source": [
    "def fill_triangulation(M):\n",
    "    '''\n",
    "    Fills all cusps but one.\n",
    "    '''\n",
    "    if M.num_cusps()==1:\n",
    "        return M\n",
    "    M=M.filled_triangulation([0])\n",
    "    M=fill_triangulation(M)\n",
    "    return M\n",
    "\n",
    "#### This is Dunfield's util.py from his exceptional census\n",
    "\n",
    "####  for a snappy manifold M descibed as a single filling of a cusp (so do filled_triangulation() as needed) \n",
    "####  the command regina_name(M) gives what regina identifies M as\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "This file provides functions for working with Regina (with a little\n",
    "help from SnapPy) to:\n",
    "\n",
    "1. Give a standard name (\"identify\") manifolds, especially Seifert and\n",
    "   graph manifolds.\n",
    "\n",
    "2. Find essential tori.\n",
    "\n",
    "3. Try to compute the JSJ decomposition.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import regina\n",
    "import snappy\n",
    "import re\n",
    "import networkx as nx\n",
    "\n",
    "def appears_hyperbolic(M):\n",
    "    acceptable = ['all tetrahedra positively oriented',\n",
    "                  'contains negatively oriented tetrahedra']\n",
    "    return M.solution_type() in acceptable and M.volume() > 0\n",
    "\n",
    "def children(packet):\n",
    "    child = packet.firstChild()\n",
    "    while child:\n",
    "        yield child\n",
    "        child = child.nextSibling()\n",
    "\n",
    "def to_regina(data):\n",
    "    if hasattr(data, '_to_string'):\n",
    "        data = data._to_string()\n",
    "    if isinstance(data, str):\n",
    "        if data.find('(') > -1:\n",
    "            data = closed_isosigs(data)[0]\n",
    "        return regina.Triangulation3(data)\n",
    "    assert isinstance(data, regina.Triangulation3)\n",
    "    return data\n",
    "\n",
    "def extract_vector(surface):\n",
    "    \"\"\"\n",
    "    Extract the raw vector of the (almost) normal surface in Regina's\n",
    "    NS_STANDARD coordinate system.\n",
    "    \"\"\"\n",
    "    S = surface\n",
    "    T = S.triangulation()\n",
    "    n = T.countTetrahedra()\n",
    "    ans = []\n",
    "    for i in range(n):\n",
    "        for j in range(4):\n",
    "            ans.append(S.triangles(i, j))\n",
    "        for j in range(3):\n",
    "            ans.append(S.quads(i, j))\n",
    "    A = regina.NormalSurface(T, regina.NS_STANDARD, ans)\n",
    "    assert A.sameSurface(S)\n",
    "    return ans\n",
    "\n",
    "def haken_sum(S1, S2):\n",
    "    T = S1.triangulation()\n",
    "    assert S1.locallyCompatible(S2)\n",
    "    v1, v2 = extract_vector(S1), extract_vector(S2)\n",
    "    sum_vec = [x1 + x2 for x1, x2 in zip(v1, v2)]\n",
    "    A = regina.NormalSurface(T, regina.NS_STANDARD, sum_vec)\n",
    "    assert S1.locallyCompatible(A) and S2.locallyCompatible(A)\n",
    "    assert S1.eulerChar() + S2.eulerChar() == A.eulerChar()\n",
    "    return A\n",
    "\n",
    "\n",
    "def census_lookup(regina_tri):\n",
    "    \"\"\"\n",
    "    Should the input triangulation be in Regina's census, return the\n",
    "    name of the manifold, dropping the triangulation number.\n",
    "    \"\"\"\n",
    "    hits = regina.Census.lookup(regina_tri)\n",
    "    hit = hits.first()\n",
    "    if hit is not None:\n",
    "        name = hit.name()\n",
    "        match = re.search('(.*) : #\\d+$', name)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "        else:\n",
    "            return match\n",
    "\n",
    "def standard_lookup(regina_tri):\n",
    "    match = regina.StandardTriangulation.isStandardTriangulation(regina_tri)\n",
    "    if match:\n",
    "        return match.manifold()\n",
    "\n",
    "def closed_isosigs(snappy_manifold, trys=20, max_tets=50):\n",
    "    \"\"\"\n",
    "    Generate a slew of 1-vertex triangulations of a closed manifold\n",
    "    using SnapPy.\n",
    "    \n",
    "    >>> M = snappy.Manifold('m004(1,2)')\n",
    "    >>> len(closed_isosigs(M, trys=5)) > 0\n",
    "    True\n",
    "    \"\"\"\n",
    "    M = snappy.Manifold(snappy_manifold)\n",
    "    assert M.cusp_info('complete?') == [False]\n",
    "    surgery_descriptions = [M.copy()]\n",
    "\n",
    "    try:\n",
    "        for curve in M.dual_curves():\n",
    "            N = M.drill(curve)\n",
    "            N.dehn_fill((1,0), 1)\n",
    "            surgery_descriptions.append(N.filled_triangulation([0]))\n",
    "    except snappy.SnapPeaFatalError:\n",
    "        pass\n",
    "\n",
    "    if len(surgery_descriptions) == 1:\n",
    "        # Try again, but unfill the cusp first to try to find more\n",
    "        # dual curves.\n",
    "        try:\n",
    "            filling = M.cusp_info(0).filling\n",
    "            N = M.copy()\n",
    "            N.dehn_fill((0, 0), 0)\n",
    "            N.randomize()\n",
    "            for curve in N.dual_curves():\n",
    "                D = N.drill(curve)\n",
    "                D.dehn_fill([filling, (1,0)])\n",
    "                surgery_descriptions.append(D.filled_triangulation([0]))\n",
    "        except snappy.SnapPeaFatalError:\n",
    "            pass\n",
    "\n",
    "    ans = set()\n",
    "    for N in surgery_descriptions:\n",
    "        for i in range(trys):\n",
    "            T = N.filled_triangulation()\n",
    "            if T._num_fake_cusps() == 1:\n",
    "                n = T.num_tetrahedra()\n",
    "                if n <= max_tets:\n",
    "                    ans.add((n, T.triangulation_isosig(decorated=False)))\n",
    "            N.randomize()\n",
    "\n",
    "    return [iso for n, iso in sorted(ans)]\n",
    "\n",
    "def best_match(matches):\n",
    "    \"\"\"\n",
    "    Prioritize the most concise description that Regina provides to\n",
    "    try to avoid things like the Seifert fibered space of a node being\n",
    "    a solid torus or having several nodes that can be condensed into a\n",
    "    single Seifert fibered piece.\n",
    "    \"\"\"\n",
    "    \n",
    "    def score(m):\n",
    "        if isinstance(m, regina.SFSpace):\n",
    "            s = 0\n",
    "        elif isinstance(m, regina.GraphLoop):\n",
    "            s = 1\n",
    "        elif isinstance(m, regina.GraphPair):\n",
    "            s = 2\n",
    "        elif isinstance(m, regina.GraphTriple):\n",
    "            s = 3\n",
    "        elif m is None:\n",
    "            s = 10000\n",
    "        else:\n",
    "            s = 4\n",
    "        return (s, str(m))\n",
    "    return min(matches, key=score)\n",
    "\n",
    "def identify_with_torus_boundary(regina_tri):\n",
    "    \"\"\"\n",
    "    Use the combined power of Regina and SnapPy to try to give a name\n",
    "    to the input manifold.\n",
    "    \"\"\"\n",
    "    \n",
    "    kind, name = None, None\n",
    "    \n",
    "    P = regina_tri.clone()\n",
    "    P.finiteToIdeal()\n",
    "    P.intelligentSimplify()\n",
    "    M = snappy.Manifold(P.isoSig())\n",
    "    M.simplify()\n",
    "    if appears_hyperbolic(M):\n",
    "        for i in range(100):\n",
    "            if M.solution_type() == 'all tetrahedra positively oriented':\n",
    "                break\n",
    "            M.randomize()\n",
    "        \n",
    "        if not M.verify_hyperbolicity(bits_prec=100):\n",
    "            raise RuntimeError('Cannot prove hyperbolicity for ' +\n",
    "                               M.triangulation_isosig())\n",
    "        kind = 'hyperbolic'\n",
    "        ids = M.identify()\n",
    "        if ids:\n",
    "            name = ids[0].name()\n",
    "    else:\n",
    "        match = standard_lookup(regina_tri)\n",
    "        if match is None:\n",
    "            Q = P.clone()\n",
    "            Q.idealToFinite()\n",
    "            Q.intelligentSimplify()\n",
    "            match = standard_lookup(Q)\n",
    "        if match is not None:\n",
    "            kind = match.__class__.__name__\n",
    "            name = str(match)\n",
    "        else:\n",
    "            name = P.isoSig()\n",
    "    return kind, name\n",
    "            \n",
    "    \n",
    "    \n",
    "\n",
    "def is_toroidal(regina_tri):\n",
    "    \"\"\"\n",
    "    Checks for essential tori and returns the pieces of the\n",
    "    associated partial JSJ decomposition.\n",
    "    \n",
    "    >>> T = to_regina('hLALAkbccfefgglpkusufk')  # m004(4,1)\n",
    "    >>> is_toroidal(T)[0]\n",
    "    True\n",
    "    >>> T = to_regina('hvLAQkcdfegfggjwajpmpw')  # m004(0,1)\n",
    "    >>> is_toroidal(T)[0]\n",
    "    True\n",
    "    >>> T = to_regina('nLLLLMLPQkcdgfihjlmmlkmlhshnrvaqtpsfnf')  # 5_2(10,1)\n",
    "    >>> T.isHaken()\n",
    "    True\n",
    "    >>> is_toroidal(T)[0]\n",
    "    False\n",
    "\n",
    "    Note: currently checks all fundamental normal tori; possibly\n",
    "    the theory lets one just check *vertex* normal tori.\n",
    "    \"\"\"\n",
    "    T = regina_tri\n",
    "    assert T.isZeroEfficient()\n",
    "    surfaces = regina.NNormalSurfaceList.enumerate(T,\n",
    "                          regina.NS_QUAD, regina.NS_FUNDAMENTAL)\n",
    "    for i in range(surfaces.size()):\n",
    "        S = surfaces.surface(i)\n",
    "        if S.eulerChar() == 0:\n",
    "            if not S.isOrientable():\n",
    "                S = S.doubleSurface()\n",
    "            assert S.isOrientable()\n",
    "            X = S.cutAlong()\n",
    "            X.intelligentSimplify()\n",
    "            X.splitIntoComponents()\n",
    "            pieces = list(children(X))\n",
    "            if all(not C.hasCompressingDisc() for C in pieces):\n",
    "                ids = [identify_with_torus_boundary(C) for C in pieces]\n",
    "                return (True, sorted(ids))\n",
    "                \n",
    "    return (False, None)\n",
    "\n",
    "\n",
    "def decompose_along_tori(regina_tri):\n",
    "    \"\"\"\n",
    "    First, finds all essential normal tori in the manifold associated\n",
    "    with fundamental normal surfaces.  Then takes a maximal disjoint\n",
    "    collection of these tori, namely the one with the fewest tori\n",
    "    involved, and cuts the manifold open along it.  It tries to\n",
    "    identify the pieces, removing any (torus x I) components. \n",
    "\n",
    "    Returns: (has essential torus, list of pieces)\n",
    "\n",
    "    Note: This may fail to be the true JSJ decomposition because there\n",
    "    could be (torus x I)'s in the list of pieces and it might well be\n",
    "    possible to amalgamate some of the pieces into a single SFS.\n",
    "    \"\"\"\n",
    "    \n",
    "    T = regina_tri\n",
    "    assert T.isZeroEfficient()\n",
    "    essential_tori = []\n",
    "    surfaces = regina.NNormalSurfaceList.enumerate(T,\n",
    "                          regina.NS_QUAD, regina.NS_FUNDAMENTAL)\n",
    "    for i in range(surfaces.size()):\n",
    "        S = surfaces.surface(i)\n",
    "        if S.eulerChar() == 0:\n",
    "            if not S.isOrientable():\n",
    "                S = S.doubleSurface()\n",
    "            assert S.isOrientable()\n",
    "            X = S.cutAlong()\n",
    "            X.intelligentSimplify()\n",
    "            X.splitIntoComponents()\n",
    "            pieces = list(children(X))\n",
    "            if all(not C.hasCompressingDisc() for C in pieces):\n",
    "                essential_tori.append(S)\n",
    "\n",
    "    if len(essential_tori) == 0:\n",
    "        return False, None\n",
    "    \n",
    "    D = nx.Graph()\n",
    "    for a, A in enumerate(essential_tori):\n",
    "        for b, B in enumerate(essential_tori):\n",
    "            if a < b:\n",
    "                if A.disjoint(B):\n",
    "                    D.add_edge(a, b)\n",
    "\n",
    "    cliques = list(nx.find_cliques(D))\n",
    "    if len(cliques) == 0:\n",
    "        clique = [0]\n",
    "    else:\n",
    "        clique = min(cliques, key=len)\n",
    "    clique = [essential_tori[c] for c in clique]\n",
    "    A = clique[0]\n",
    "    for B in clique[1:]:\n",
    "        A = haken_sum(A, B)\n",
    "\n",
    "    X = A.cutAlong()\n",
    "    X.intelligentSimplify()\n",
    "    X.splitIntoComponents()\n",
    "    ids = [identify_with_torus_boundary(C) for C in list(children(X))]\n",
    "    # Remove products\n",
    "    ids = [i for i in ids if i[1] not in ('SFS [A: (1,1)]', 'A x S1')]\n",
    "    return (True, sorted(ids))\n",
    "\n",
    "def regina_name(closed_snappy_manifold, trys=100):\n",
    "    \"\"\"\n",
    "    >>> regina_name('m004(1,0)')\n",
    "    'S3'\n",
    "    >>> regina_name('s006(-2, 1)')\n",
    "    'SFS [A: (5,1)] / [ 0,-1 | -1,0 ]'\n",
    "    >>> regina_name('m010(-1, 1)')\n",
    "    'L(3,1) # RP3'\n",
    "    >>> regina_name('m022(-1,1)')\n",
    "    'SFS [S2: (3,2) (3,2) (4,-3)]'\n",
    "    >>> regina_name('v0004(0, 1)')\n",
    "    'SFS [S2: (2,1) (4,1) (15,-13)]'\n",
    "    >>> regina_name('m305(1, 0)')\n",
    "    'L(3,1) # RP3'\n",
    "    \"\"\"\n",
    "    M = snappy.Manifold(closed_snappy_manifold)\n",
    "    isosigs = closed_isosigs(M, trys=trys, max_tets=25)\n",
    "    if len(isosigs) == 0:\n",
    "        return\n",
    "    T = to_regina(isosigs[0])\n",
    "    if T.isIrreducible():\n",
    "        if T.countTetrahedra() <= 11:\n",
    "            for i in range(3):\n",
    "                T.simplifyExhaustive(i)\n",
    "                name = census_lookup(T)\n",
    "                if name is not None:\n",
    "                    return name\n",
    "            \n",
    "        matches = [standard_lookup(to_regina(iso)) for iso in isosigs]\n",
    "        match = best_match(matches)\n",
    "        if match is not None:\n",
    "            return str(match)\n",
    "    else:\n",
    "        T.connectedSumDecomposition()\n",
    "        pieces = [regina_name(P) for P in children(T)]\n",
    "        if None not in pieces:\n",
    "            return ' # '.join(sorted(pieces))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import doctest\n",
    "    print(doctest.testmod())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from multiprocessing import Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_with_time_limit(func, args, time):\n",
    "    \"\"\"\n",
    "    Runs function until finished or time limit reached\n",
    "    Input: \n",
    "        - func (callable) Function to be run\n",
    "        - arg () Arguments of func\n",
    "        - time (int) Time limit in seconds\n",
    "    Return:\n",
    "        (bool) True if function ran, False if time limit reached\n",
    "    \"\"\"\n",
    "    prc = Process(target=func,args=args)\n",
    "    prc.start() #Starts computing\n",
    "    prc.join(time) \n",
    "    if prc.is_alive(): #checks if computation is still running\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def recognize_mfd(knot):\n",
    "    \"\"\"\n",
    "    Uses regina and snappy to recognize the name of its 0-filling.\n",
    "    \"\"\"\n",
    "    K=snappy.Manifold(knot)\n",
    "    K.dehn_fill((0,1))\n",
    "    K_reg=regina_name(K)\n",
    "    if K_reg is not None:\n",
    "        print([knot,K_reg])\n",
    "        with open(\"regina_names.csv\", \"a\") as output: #Opens output file # Use the a parameter to add a row\n",
    "            csvwriter = csv.writer(output, delimiter = \",\")\n",
    "            csvwriter.writerow((knot, K_reg))\n",
    "    else:\n",
    "        try:\n",
    "            K_reg=decompose_along_tori(to_regina(closed_isosigs(K)[0]))\n",
    "        except TypeError:\n",
    "            K_reg=None\n",
    "        if K_reg is not None and K_reg[0]==True:\n",
    "            print([knot,'JSJ'+str(K_reg[1])])\n",
    "            with open(\"regina_names.csv\", \"a\") as output: #Opens output file # Use the a parameter to add a row\n",
    "                csvwriter = csv.writer(output, delimiter = \",\")\n",
    "                csvwriter.writerow((knot,'JSJ'+str(K_reg[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['K3a1', 'SFS [S2: (2,1) (3,1) (6,-5)]']\n",
      "['K4a1', 'T x I / [ 2,1 | 1,1 ]']\n",
      "['K5a1', 'SFS [A: (2,1)] / [ 0,1 | 1,-1 ]']\n",
      "['K5a2', 'SFS [S2: (2,1) (5,2) (10,-9)]']\n",
      "['K6a3', 'SFS [A: (2,1)] / [ 0,1 | 1,-2 ]']\n",
      "['K7a4', 'SFS [A: (3,2)] / [ 0,1 | 1,-1 ]']\n",
      "['K7a7', 'SFS [S2: (2,1) (7,3) (14,-13)]']\n",
      "['K8a11', 'SFS [A: (3,1)] / [ 0,1 | 1,-2 ]']\n",
      "['K8a18', \"JSJ[('SFSpace', 'SFS [A: (2,1)]'), ('SFSpace', 'SFS [A: (2,1)]')]\"]\n",
      "['K8n1', 'SFS [D: (2,1) (2,1)] U/m SFS [D: (3,1) (3,2)], m = [ 0,1 | 1,0 ]']\n",
      "['K8n3', 'SFS [S2: (3,2) (4,1) (12,-11)]']\n",
      "['K9a27', 'SFS [A: (4,3)] / [ 0,1 | 1,-1 ]']\n",
      "['K9a36', \"JSJ[('SFSpace', 'SFS [A: (2,3)]'), ('SFSpace', 'SFS [A: (3,1)]')]\"]\n",
      "['K9a40', \"JSJ[('hyperbolic', 'm202')]\"]\n",
      "['K9a41', 'SFS [S2: (2,1) (9,4) (18,-17)]']\n",
      "['K9n5', 'SFS [A: (2,1)] / [ -1,3 | 1,-2 ]']\n",
      "['K10a75', 'SFS [A: (4,1)] / [ 0,1 | 1,-2 ]']\n",
      "['K10a117', \"JSJ[('SFSpace', 'SFS [A: (2,1)]'), ('SFSpace', 'SFS [A: (3,5)]')]\"]\n",
      "['K10n13', 'SFS [S2: (2,1) (5,1) (10,-7)]']\n",
      "['K10n21', 'SFS [S2: (3,1) (5,3) (15,-14)]']\n",
      "['K10n29', 'SFS [D: (2,1) (2,1)] U/m SFS [D: (3,1) (3,2)], m = [ -1,2 | 0,1 ]']\n",
      "['K11a247', 'SFS [A: (5,4)] / [ 0,1 | 1,-1 ]']\n",
      "['K11a362', \"JSJ[('hyperbolic', 'm357')]\"]\n",
      "['K11a363', \"JSJ[('SFSpace', 'SFS [A: (3,1)]'), ('SFSpace', 'SFS [A: (3,2)]')]\"]\n",
      "The runtime was too long for: ['K11a367']\n",
      "['K11n139', 'SFS [A: (2,1)] / [ 2,5 | 1,2 ]']\n",
      "['K11n141', \"JSJ[('hyperbolic', 'm125')]\"]\n",
      "['K12a803', 'SFS [A: (5,1)] / [ 0,1 | 1,-2 ]']\n",
      "['K12a1287', \"JSJ[('SFSpace', 'SFS [A: (3,1)]'), ('SFSpace', 'SFS [A: (3,4)]')]\"]\n",
      "['K12n121', 'SFS [D: (2,1) (2,1)] U/m SFS [D: (2,1) (3,1)], m = [ 5,1 | 4,1 ]']\n",
      "['K12n582', 'SFS [D: (2,1) (2,1)] U/m SFS [D: (3,1) (3,2)], m = [ -2,3 | -1,2 ]']\n",
      "['K12n721', \"JSJ[('SFSpace', 'SFS [D: (2,1) (2,-1)]'), ('hyperbolic', 'm043')]\"]\n",
      "['K13a3143', 'SFS [A: (6,5)] / [ 0,1 | 1,-1 ]']\n",
      "['K13a4573', \"JSJ[('SFSpace', 'SFS [A: (2,1)]'), ('SFSpace', 'SFS [A: (5,4)]')]\"]\n",
      "['K13a4843', \"JSJ[('hyperbolic', 's548')]\"]\n",
      "['K13a4856', \"JSJ[('SFSpace', 'SFS [A: (3,1)]'), ('SFSpace', 'SFS [A: (4,3)]')]\"]\n",
      "The runtime was too long for: ['K13a4873']\n",
      "['K13a4873', \"JSJ[('hyperbolic', 's876')]\"]\n",
      "The runtime was too long for: ['K13a4878']\n",
      "['K13n469', \"JSJ[('SFSpace', 'SFS [D: (2,1) (2,-1)]'), ('hyperbolic', 'm004')]\"]\n",
      "['K13n3521', \"JSJ[('hyperbolic', 'm329')]\"]\n",
      "['K13n3523', 'SFS [A: (2,1)] / [ 2,7 | 1,3 ]']\n",
      "['K13n3594', \"JSJ[('hyperbolic', 'm292')]\"]\n",
      "['K13n3596', \"JSJ[('SFSpace', 'SFS [D: (2,1) (3,-2)]'), ('SFSpace', 'SFS [Or, g=0 + 3 punctures: (1,3)]')]\"]\n",
      "['K13n3663', \"JSJ[('SFSpace', 'SFS [D: (2,1) (3,-2)]'), ('SFSpace', 'SFS [Or, g=0 + 3 punctures: (1,1)]')]\"]\n",
      "['K13n4587', 'SFS [D: (2,1) (3,1)] U/m SFS [D: (2,1) (14,1)], m = [ -3,5 | -1,2 ]']\n",
      "['K13n4639', 'SFS [D: (2,1) (3,1)] U/m SFS [D: (2,1) (10,1)], m = [ -5,7 | -2,3 ]']\n",
      "['K14a12741', 'SFS [A: (6,1)] / [ 0,1 | 1,-2 ]']\n",
      "['K14a17730', \"JSJ[('SFSpace', 'SFS [A: (2,1)]'), ('SFSpace', 'SFS [A: (5,9)]')]\"]\n",
      "['K14a19429', \"JSJ[('SFSpace', 'SFS [A: (3,4)]'), ('SFSpace', 'SFS [A: (4,1)]')]\"]\n",
      "['K14n3611', \"JSJ[('SFSpace', 'M/n2 x~ S1'), ('hyperbolic', 'm015')]\"]\n",
      "['K14n18212', 'SFS [D: (2,1) (2,1)] U/m SFS [D: (3,1) (3,2)], m = [ -3,4 | -2,3 ]']\n",
      "The runtime was too long for: ['K14n19265']\n",
      "The runtime was too long for: ['K14n21881']\n",
      "['K14n19265', \"JSJ[('hyperbolic', 'v3319')]\"]\n",
      "['K14n21882', 'SFS [D: (2,1) (2,1)] U/m SFS [D: (3,1) (6,1)], m = [ 1,1 | 0,1 ]']\n",
      "['K14n22073', 'SFS [D: (2,1) (3,1)] U/m SFS [A: (2,1) (2,1)] U/n SFS [D: (2,1) (3,2)], m = [ 1,-1 | 0,-1 ], n = [ 0,1 | 1,1 ]']\n",
      "['K14n22180', \"JSJ[('SFSpace', 'SFS [D: (2,1) (3,-2)]'), ('SFSpace', 'SFS [Or, g=0 + 3 punctures: (1,1)]')]\"]\n",
      "['K14n22185', \"JSJ[('SFSpace', 'SFS [D: (2,1) (2,-1)]'), ('hyperbolic', 'm137')]\"]\n",
      "['K14n22589', \"JSJ[('hyperbolic', 'm129')]\"]\n",
      "['K14n24553', \"JSJ[('SFSpace', 'SFS [D: (2,1) (2,-1)]'), ('hyperbolic', 's663')]\"]\n",
      "['K14n26039', \"JSJ[('SFSpace', 'Or, g=0 + 3 punctures x S1'), ('SFSpace', 'SFS [D: (2,1) (3,-2)]')]\"]\n",
      "['K15a54894', 'SFS [A: (7,6)] / [ 0,1 | 1,-1 ]']\n",
      "['K15a78880', \"JSJ[('SFSpace', 'SFS [A: (2,1)]'), ('SFSpace', 'SFS [A: (6,5)]')]\"]\n",
      "The runtime was too long for: ['K15a84844']\n",
      "['K15a84844', \"JSJ[('hyperbolic', 'v1203')]\"]\n",
      "['K15a84969', \"JSJ[('SFSpace', 'SFS [A: (3,1)]'), ('SFSpace', 'SFS [A: (5,4)]')]\"]\n",
      "The runtime was too long for: ['K15a85213']\n",
      "['K15a85234', \"JSJ[('SFSpace', 'SFS [A: (4,1)]'), ('SFSpace', 'SFS [A: (4,7)]')]\"]\n",
      "['K15a85213', \"JSJ[('hyperbolic', 'v2601')]\"]\n",
      "The runtime was too long for: ['K15a85257']\n",
      "The runtime was too long for: ['K15a85263']\n",
      "['K15n19499', \"JSJ[('SFSpace', 'SFS [D: (2,1) (2,-1)]'), ('hyperbolic', 'm032')]\"]\n",
      "['K15a85257', \"JSJ[('hyperbolic', 'v3461')]\"]\n",
      "The runtime was too long for: ['K15n30281']\n",
      "['K15n40211', 'SFS [D: (2,1) (3,1)] U/m SFS [D: (2,1) (18,1)], m = [ -1,3 | 0,1 ]']\n",
      "The runtime was too long for: ['K15n41185']\n",
      "['K15n43522', 'SFS [A: (2,1)] / [ 3,11 | 2,7 ]']\n",
      "The runtime was too long for: ['K15n48968']\n",
      "['K15n48968', \"JSJ[('SFSpace', 'M/n2 x~ S1'), ('hyperbolic', 'v2817')]\"]\n",
      "['K15n51748', \"JSJ[('SFSpace', 'SFS [D: (2,1) (2,-1)]'), ('hyperbolic', 'm137')]\"]\n",
      "['K15n59184', \"JSJ[('SFSpace', 'Or, g=0 + 3 punctures x S1'), ('SFSpace', 'SFS [D: (2,1) (3,-2)]')]\"]\n",
      "['K15n72303', \"JSJ[('SFSpace', 'M/n2 x~ S1'), ('hyperbolic', 's493')]\"]\n",
      "['K15n112477', \"JSJ[('hyperbolic', 's503')]\"]\n",
      "['K15n112479', 'SFS [A: (2,1)] / [ 2,9 | 1,4 ]']\n",
      "The runtime was too long for: ['K15n113773']\n",
      "['K15n113773', \"JSJ[('hyperbolic', 's843')]\"]\n",
      "['K15n113775', \"JSJ[('hyperbolic', 'm129')]\"]\n",
      "The runtime was too long for: ['K15n113923']\n",
      "['K15n113923', \"JSJ[('hyperbolic', 's441')]\"]\n",
      "['K15n115375', \"JSJ[('hyperbolic', 'm129')]\"]\n",
      "['K15n115646', \"JSJ[('SFSpace', 'SFS [D: (2,1) (3,-2)]'), ('SFSpace', 'SFS [Or, g=0 + 3 punctures: (1,1)]')]\"]\n",
      "['K15n124802', 'SFS [D: (2,1) (3,1)] U/m SFS [D: (2,1) (6,1)], m = [ -7,9 | -3,4 ]']\n",
      "The runtime was too long for: ['K15n142188']\n",
      "['K15n153789', \"JSJ[('SFSpace', 'SFS [D: (2,1) (2,-1)]'), ('hyperbolic', 'm032')]\"]\n",
      "The runtime was too long for: ['K15n156076']\n",
      "The runtime was too long for: ['K15n160926']\n",
      "The runtime was too long for: ['K15n164338']\n",
      "Total time taken: 0.24664242015944587 hours\n",
      "['K15n164338', \"JSJ[('hyperbolic', 's906')]\"]\n",
      "['K15n160926', \"JSJ[('hyperbolic', 't11128')]\"]\n",
      "['K15n156076', \"JSJ[('SFSpace', 'SFS [D: (2,1) (3,-2)]'), ('hyperbolic', None)]\"]\n",
      "['K15n142188', \"JSJ[('SFSpace', 'SFS [D: (2,1) (3,-2)]'), ('hyperbolic', None)]\"]\n"
     ]
    }
   ],
   "source": [
    "start_time_global=time.time()\n",
    "\n",
    "\n",
    "for knot in unclear_volumes:\n",
    "    args = (knot)\n",
    "    run_value = run_with_time_limit(recognize_mfd, args, 20)\n",
    "    if run_value == False:\n",
    "        print('The runtime was too long for:',knot)\n",
    "print('Total time taken:',(time.time()-start_time_global)/3600,'hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n"
     ]
    }
   ],
   "source": [
    "regina_names=[]\n",
    "\n",
    "with open('regina_names.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        regina_names.append(row)\n",
    "print(len(regina_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['K3a1', 'SFS [S2: (2,1) (3,1) (6,-5)]'],\n",
       " ['K4a1', 'T x I / [ 2,1 | 1,1 ]'],\n",
       " ['K5a1', 'SFS [A: (2,1)] / [ 0,1 | 1,-1 ]'],\n",
       " ['K5a2', 'SFS [S2: (2,1) (5,2) (10,-9)]'],\n",
       " ['K6a3', 'SFS [A: (2,1)] / [ 0,1 | 1,-2 ]'],\n",
       " ['K7a4', 'SFS [A: (3,2)] / [ 0,1 | 1,-1 ]'],\n",
       " ['K7a7', 'SFS [S2: (2,1) (7,3) (14,-13)]'],\n",
       " ['K8a11', 'SFS [A: (3,1)] / [ 0,1 | 1,-2 ]'],\n",
       " ['K8a18',\n",
       "  \"JSJ[('SFSpace', 'SFS [A: (2,1)]'), ('SFSpace', 'SFS [A: (2,1)]')]\"],\n",
       " ['K8n1', 'SFS [D: (2,1) (2,1)] U/m SFS [D: (3,1) (3,2)], m = [ 0,1 | 1,0 ]'],\n",
       " ['K8n3', 'SFS [S2: (3,2) (4,1) (12,-11)]'],\n",
       " ['K9a27', 'SFS [A: (4,3)] / [ 0,1 | 1,-1 ]'],\n",
       " ['K9a36',\n",
       "  \"JSJ[('SFSpace', 'SFS [A: (2,3)]'), ('SFSpace', 'SFS [A: (3,1)]')]\"],\n",
       " ['K9a40', \"JSJ[('hyperbolic', 'm202')]\"],\n",
       " ['K9a41', 'SFS [S2: (2,1) (9,4) (18,-17)]'],\n",
       " ['K9n5', 'SFS [A: (2,1)] / [ -1,3 | 1,-2 ]'],\n",
       " ['K10a75', 'SFS [A: (4,1)] / [ 0,1 | 1,-2 ]'],\n",
       " ['K10a117',\n",
       "  \"JSJ[('SFSpace', 'SFS [A: (2,1)]'), ('SFSpace', 'SFS [A: (3,5)]')]\"],\n",
       " ['K10n13', 'SFS [S2: (2,1) (5,1) (10,-7)]'],\n",
       " ['K10n21', 'SFS [S2: (3,1) (5,3) (15,-14)]'],\n",
       " ['K10n29',\n",
       "  'SFS [D: (2,1) (2,1)] U/m SFS [D: (3,1) (3,2)], m = [ -1,2 | 0,1 ]'],\n",
       " ['K11a247', 'SFS [A: (5,4)] / [ 0,1 | 1,-1 ]'],\n",
       " ['K11a362', \"JSJ[('hyperbolic', 'm357')]\"],\n",
       " ['K11a363',\n",
       "  \"JSJ[('SFSpace', 'SFS [A: (3,1)]'), ('SFSpace', 'SFS [A: (3,2)]')]\"],\n",
       " ['K11n139', 'SFS [A: (2,1)] / [ 2,5 | 1,2 ]'],\n",
       " ['K11n141', \"JSJ[('hyperbolic', 'm125')]\"],\n",
       " ['K12a803', 'SFS [A: (5,1)] / [ 0,1 | 1,-2 ]'],\n",
       " ['K12a1287',\n",
       "  \"JSJ[('SFSpace', 'SFS [A: (3,1)]'), ('SFSpace', 'SFS [A: (3,4)]')]\"],\n",
       " ['K12n121',\n",
       "  'SFS [D: (2,1) (2,1)] U/m SFS [D: (2,1) (3,1)], m = [ 5,1 | 4,1 ]'],\n",
       " ['K12n582',\n",
       "  'SFS [D: (2,1) (2,1)] U/m SFS [D: (3,1) (3,2)], m = [ -2,3 | -1,2 ]'],\n",
       " ['K12n721',\n",
       "  \"JSJ[('SFSpace', 'SFS [D: (2,1) (2,-1)]'), ('hyperbolic', 'm043')]\"],\n",
       " ['K13a3143', 'SFS [A: (6,5)] / [ 0,1 | 1,-1 ]'],\n",
       " ['K13a4573',\n",
       "  \"JSJ[('SFSpace', 'SFS [A: (2,1)]'), ('SFSpace', 'SFS [A: (5,4)]')]\"],\n",
       " ['K13a4843', \"JSJ[('hyperbolic', 's548')]\"],\n",
       " ['K13a4856',\n",
       "  \"JSJ[('SFSpace', 'SFS [A: (3,1)]'), ('SFSpace', 'SFS [A: (4,3)]')]\"],\n",
       " ['K13a4873', \"JSJ[('hyperbolic', 's876')]\"],\n",
       " ['K13n469',\n",
       "  \"JSJ[('SFSpace', 'SFS [D: (2,1) (2,-1)]'), ('hyperbolic', 'm004')]\"],\n",
       " ['K13n3521', \"JSJ[('hyperbolic', 'm329')]\"],\n",
       " ['K13n3523', 'SFS [A: (2,1)] / [ 2,7 | 1,3 ]'],\n",
       " ['K13n3594', \"JSJ[('hyperbolic', 'm292')]\"],\n",
       " ['K13n3596',\n",
       "  \"JSJ[('SFSpace', 'SFS [D: (2,1) (3,-2)]'), ('SFSpace', 'SFS [Or, g=0 + 3 punctures: (1,3)]')]\"],\n",
       " ['K13n3663',\n",
       "  \"JSJ[('SFSpace', 'SFS [D: (2,1) (3,-2)]'), ('SFSpace', 'SFS [Or, g=0 + 3 punctures: (1,1)]')]\"],\n",
       " ['K13n4587',\n",
       "  'SFS [D: (2,1) (3,1)] U/m SFS [D: (2,1) (14,1)], m = [ -3,5 | -1,2 ]'],\n",
       " ['K13n4639',\n",
       "  'SFS [D: (2,1) (3,1)] U/m SFS [D: (2,1) (10,1)], m = [ -5,7 | -2,3 ]'],\n",
       " ['K14a12741', 'SFS [A: (6,1)] / [ 0,1 | 1,-2 ]'],\n",
       " ['K14a17730',\n",
       "  \"JSJ[('SFSpace', 'SFS [A: (2,1)]'), ('SFSpace', 'SFS [A: (5,9)]')]\"],\n",
       " ['K14a19429',\n",
       "  \"JSJ[('SFSpace', 'SFS [A: (3,4)]'), ('SFSpace', 'SFS [A: (4,1)]')]\"],\n",
       " ['K14n3611', \"JSJ[('SFSpace', 'M/n2 x~ S1'), ('hyperbolic', 'm015')]\"],\n",
       " ['K14n18212',\n",
       "  'SFS [D: (2,1) (2,1)] U/m SFS [D: (3,1) (3,2)], m = [ -3,4 | -2,3 ]'],\n",
       " ['K14n19265', \"JSJ[('hyperbolic', 'v3319')]\"],\n",
       " ['K14n21882',\n",
       "  'SFS [D: (2,1) (2,1)] U/m SFS [D: (3,1) (6,1)], m = [ 1,1 | 0,1 ]'],\n",
       " ['K14n22073',\n",
       "  'SFS [D: (2,1) (3,1)] U/m SFS [A: (2,1) (2,1)] U/n SFS [D: (2,1) (3,2)], m = [ 1,-1 | 0,-1 ], n = [ 0,1 | 1,1 ]'],\n",
       " ['K14n22180',\n",
       "  \"JSJ[('SFSpace', 'SFS [D: (2,1) (3,-2)]'), ('SFSpace', 'SFS [Or, g=0 + 3 punctures: (1,1)]')]\"],\n",
       " ['K14n22185',\n",
       "  \"JSJ[('SFSpace', 'SFS [D: (2,1) (2,-1)]'), ('hyperbolic', 'm137')]\"],\n",
       " ['K14n22589', \"JSJ[('hyperbolic', 'm129')]\"],\n",
       " ['K14n24553',\n",
       "  \"JSJ[('SFSpace', 'SFS [D: (2,1) (2,-1)]'), ('hyperbolic', 's663')]\"],\n",
       " ['K14n26039',\n",
       "  \"JSJ[('SFSpace', 'Or, g=0 + 3 punctures x S1'), ('SFSpace', 'SFS [D: (2,1) (3,-2)]')]\"],\n",
       " ['K15a54894', 'SFS [A: (7,6)] / [ 0,1 | 1,-1 ]'],\n",
       " ['K15a78880',\n",
       "  \"JSJ[('SFSpace', 'SFS [A: (2,1)]'), ('SFSpace', 'SFS [A: (6,5)]')]\"],\n",
       " ['K15a84844', \"JSJ[('hyperbolic', 'v1203')]\"],\n",
       " ['K15a84969',\n",
       "  \"JSJ[('SFSpace', 'SFS [A: (3,1)]'), ('SFSpace', 'SFS [A: (5,4)]')]\"],\n",
       " ['K15a85234',\n",
       "  \"JSJ[('SFSpace', 'SFS [A: (4,1)]'), ('SFSpace', 'SFS [A: (4,7)]')]\"],\n",
       " ['K15a85213', \"JSJ[('hyperbolic', 'v2601')]\"],\n",
       " ['K15n19499',\n",
       "  \"JSJ[('SFSpace', 'SFS [D: (2,1) (2,-1)]'), ('hyperbolic', 'm032')]\"],\n",
       " ['K15a85257', \"JSJ[('hyperbolic', 'v3461')]\"],\n",
       " ['K15n40211',\n",
       "  'SFS [D: (2,1) (3,1)] U/m SFS [D: (2,1) (18,1)], m = [ -1,3 | 0,1 ]'],\n",
       " ['K15n43522', 'SFS [A: (2,1)] / [ 3,11 | 2,7 ]'],\n",
       " ['K15n48968', \"JSJ[('SFSpace', 'M/n2 x~ S1'), ('hyperbolic', 'v2817')]\"],\n",
       " ['K15n51748',\n",
       "  \"JSJ[('SFSpace', 'SFS [D: (2,1) (2,-1)]'), ('hyperbolic', 'm137')]\"],\n",
       " ['K15n59184',\n",
       "  \"JSJ[('SFSpace', 'Or, g=0 + 3 punctures x S1'), ('SFSpace', 'SFS [D: (2,1) (3,-2)]')]\"],\n",
       " ['K15n72303', \"JSJ[('SFSpace', 'M/n2 x~ S1'), ('hyperbolic', 's493')]\"],\n",
       " ['K15n112477', \"JSJ[('hyperbolic', 's503')]\"],\n",
       " ['K15n112479', 'SFS [A: (2,1)] / [ 2,9 | 1,4 ]'],\n",
       " ['K15n113773', \"JSJ[('hyperbolic', 's843')]\"],\n",
       " ['K15n113775', \"JSJ[('hyperbolic', 'm129')]\"],\n",
       " ['K15n113923', \"JSJ[('hyperbolic', 's441')]\"],\n",
       " ['K15n115375', \"JSJ[('hyperbolic', 'm129')]\"],\n",
       " ['K15n115646',\n",
       "  \"JSJ[('SFSpace', 'SFS [D: (2,1) (3,-2)]'), ('SFSpace', 'SFS [Or, g=0 + 3 punctures: (1,1)]')]\"],\n",
       " ['K15n124802',\n",
       "  'SFS [D: (2,1) (3,1)] U/m SFS [D: (2,1) (6,1)], m = [ -7,9 | -3,4 ]'],\n",
       " ['K15n153789',\n",
       "  \"JSJ[('SFSpace', 'SFS [D: (2,1) (2,-1)]'), ('hyperbolic', 'm032')]\"],\n",
       " ['K15n164338', \"JSJ[('hyperbolic', 's906')]\"],\n",
       " ['K15n160926', \"JSJ[('hyperbolic', 't11128')]\"],\n",
       " ['K15n156076',\n",
       "  \"JSJ[('SFSpace', 'SFS [D: (2,1) (3,-2)]'), ('hyperbolic', None)]\"],\n",
       " ['K15n142188',\n",
       "  \"JSJ[('SFSpace', 'SFS [D: (2,1) (3,-2)]'), ('hyperbolic', None)]\"]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regina_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['K7a6'],\n",
       " ['K11a343'],\n",
       " ['K11a367'],\n",
       " ['K12a1166'],\n",
       " ['K12n309'],\n",
       " ['K13a4878'],\n",
       " ['K13n1021'],\n",
       " ['K14n14254'],\n",
       " ['K14n21881'],\n",
       " ['K15a85263'],\n",
       " ['K15n27975'],\n",
       " ['K15n30281'],\n",
       " ['K15n41185'],\n",
       " ['K15n94464'],\n",
       " ['K15n101402']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unclear_volumes=[x for x in unclear_volumes if x[0] not in [y[0] for y in regina_names]]\n",
    "unclear_volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unclear_volumes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The runtime was too long for: ['K11a367']\n",
      "The runtime was too long for: ['K13a4878']\n",
      "The runtime was too long for: ['K14n21881']\n",
      "The runtime was too long for: ['K15a85263']\n",
      "The runtime was too long for: ['K15n41185']\n",
      "Total time taken: 0.1754022287660175 hours\n"
     ]
    }
   ],
   "source": [
    "start_time_global=time.time()\n",
    "\n",
    "\n",
    "for knot in unclear_volumes:\n",
    "    args = (knot)\n",
    "    run_value = run_with_time_limit(recognize_mfd, args, 100)\n",
    "    if run_value == False:\n",
    "        print('The runtime was too long for:',knot)\n",
    "print('Total time taken:',(time.time()-start_time_global)/3600,'hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n"
     ]
    }
   ],
   "source": [
    "regina_names=[]\n",
    "\n",
    "with open('regina_names.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        regina_names.append(row)\n",
    "print(len(regina_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['K7a6'],\n",
       " ['K11a343'],\n",
       " ['K11a367'],\n",
       " ['K12a1166'],\n",
       " ['K12n309'],\n",
       " ['K13a4878'],\n",
       " ['K13n1021'],\n",
       " ['K14n14254'],\n",
       " ['K14n21881'],\n",
       " ['K15a85263'],\n",
       " ['K15n27975'],\n",
       " ['K15n30281'],\n",
       " ['K15n41185'],\n",
       " ['K15n94464'],\n",
       " ['K15n101402']]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unclear_volumes=[x for x in unclear_volumes if x[0] not in [y[0] for y in regina_names]]\n",
    "unclear_volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The runtime was too long for: ['K11a367']\n",
      "The runtime was too long for: ['K13a4878']\n",
      "The runtime was too long for: ['K15a85263']\n",
      "The runtime was too long for: ['K15n41185']\n",
      "Total time taken: 0.4273097668091456 hours\n"
     ]
    }
   ],
   "source": [
    "start_time_global=time.time()\n",
    "\n",
    "\n",
    "for knot in unclear_volumes:\n",
    "    args = (knot)\n",
    "    run_value = run_with_time_limit(recognize_mfd, args, 300)\n",
    "    if run_value == False:\n",
    "        print('The runtime was too long for:',knot)\n",
    "print('Total time taken:',(time.time()-start_time_global)/3600,'hours')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems that regina cannot recognize the remaining 15 manifolds. We try again to show that they are hyperbolic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['K12n309', 3.702897321857?]\n",
      "['K13n1021', 4.455978629569?]\n",
      "['K14n14254', 3.702897321857?]\n",
      "['K15n27975', 4.90264390573?]\n",
      "['K15n30281', 8.12237299081?]\n",
      "['K15n94464', 6.10429327100?]\n",
      "['K15n101402', 4.455978629569?]\n",
      "--- Time taken: 0.028645431598027547 hours ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "more_volumes=[]\n",
    "\n",
    "for x in unclear_volumes:\n",
    "    K=snappy.Manifold(x[0])\n",
    "    K.dehn_fill((0,1))\n",
    "    vol=better_volume(K,try_hard=True)\n",
    "    if vol!=0:\n",
    "        more_volumes.append([x[0],vol])\n",
    "        print([x[0],vol])\n",
    "    if vol==0:\n",
    "        vol=better_volume(K,try_hard=True,index=1000)\n",
    "        if vol!=0:\n",
    "            more_volumes.append([x[0],vol])\n",
    "            print([x[0],vol])\n",
    "print(\"--- Time taken: %s hours ---\" % ((time.time() - start_time)/3600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('more_volumes.pickle', 'wb') as f:\n",
    "    pickle.dump(more_volumes, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['K7a6'],\n",
       " ['K11a343'],\n",
       " ['K11a367'],\n",
       " ['K12a1166'],\n",
       " ['K13a4878'],\n",
       " ['K14n21881'],\n",
       " ['K15a85263'],\n",
       " ['K15n41185']]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unclear_volumes=[x for x in unclear_volumes if x[0] not in [y[0] for y in more_volumes]]\n",
    "unclear_volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Time taken: 0.07232349077860514 hours ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for x in unclear_volumes:\n",
    "    K=snappy.Manifold(x[0])\n",
    "    K.dehn_fill((0,1))\n",
    "    vol=better_volume(K,try_hard=True)\n",
    "    if vol!=0:\n",
    "        more_volumes.append([x[0],vol])\n",
    "        print([x[0],vol])\n",
    "    if vol==0:\n",
    "        vol=better_volume(K,try_hard=True,index=3000)\n",
    "        if vol!=0:\n",
    "            more_volumes.append([x[0],vol])\n",
    "            print([x[0],vol])\n",
    "print(\"--- Time taken: %s hours ---\" % ((time.time() - start_time)/3600))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try harder to find positive triangulations for the remaining 8 examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_positive_triangulations(manifold,number=1,tries=100):\n",
    "    '''\n",
    "    Searches for one triangulation with a positive solution type.\n",
    "    (Or if number is set to a different value also for different such triangulations.)\n",
    "    '''\n",
    "    M = manifold.copy()\n",
    "    pos_triangulations=[]\n",
    "    for i in range(tries):\n",
    "        if all_positive(M):\n",
    "            pos_triangulations.append(M)\n",
    "            if len(pos_triangulations)==number:\n",
    "                return pos_triangulations\n",
    "            break\n",
    "        M.randomize()\n",
    "    for i in M.dual_curves():\n",
    "        Mi = M.drill(i)\n",
    "        Mi = Mi.filled_triangulation()\n",
    "        Mi.dehn_fill((1,0),-1)\n",
    "        for q in range(tries):\n",
    "            if all_positive(Mi):\n",
    "                pos_triangulations.append(Mi)\n",
    "                if len(pos_triangulations)==number:\n",
    "                    return pos_triangulations\n",
    "                break\n",
    "            Mi.randomize()\n",
    "    for i in M.dual_curves():\n",
    "        Mi = M.drill(i)\n",
    "        Mi = Mi.filled_triangulation()\n",
    "        Mi.dehn_fill((1,0),-1)\n",
    "        for j in Mi.dual_curves():\n",
    "            Mij = Mi.drill(j)\n",
    "            Mij = Mij.filled_triangulation()\n",
    "            Mij.dehn_fill((1,0),-1)\n",
    "            for q in range(tries):\n",
    "                if all_positive(Mij):\n",
    "                    pos_triangulations.append(Mij)\n",
    "                    if len(pos_triangulations)==number:\n",
    "                        return pos_triangulations\n",
    "                    break\n",
    "                Mij.randomize()\n",
    "    for i in M.dual_curves():\n",
    "        Mi = M.drill(i)\n",
    "        Mi = Mi.filled_triangulation()\n",
    "        Mi.dehn_fill((1,0),-1)\n",
    "        for j in Mi.dual_curves():\n",
    "            Mij = Mi.drill(j)\n",
    "            Mij = Mij.filled_triangulation()\n",
    "            Mij.dehn_fill((1,0),-1)\n",
    "            for k in Mij.dual_curves():\n",
    "                Mijk = Mij.drill(k)\n",
    "                Mijk = Mijk.filled_triangulation()\n",
    "                Mijk.dehn_fill((1,0),-1)\n",
    "                for q in range(tries):\n",
    "                    if all_positive(Mijk):\n",
    "                        pos_triangulations.append(Mijk)\n",
    "                        if len(pos_triangulations)==number:\n",
    "                            return pos_triangulations\n",
    "                        break\n",
    "                    Mijk.randomize()      \n",
    "    for i in M.dual_curves():\n",
    "        Mi = M.drill(i)\n",
    "        Mi = Mi.filled_triangulation()\n",
    "        Mi.dehn_fill((1,0),-1)\n",
    "        for j in Mi.dual_curves():\n",
    "            Mij = Mi.drill(j)\n",
    "            Mij = Mij.filled_triangulation()\n",
    "            Mij.dehn_fill((1,0),-1)\n",
    "            for k in Mij.dual_curves():\n",
    "                Mijk = Mij.drill(k)\n",
    "                Mijk = Mijk.filled_triangulation()\n",
    "                Mijk.dehn_fill((1,0),-1)\n",
    "                for l in Mijk.dual_curves():\n",
    "                    Mijkl = Mijk.drill(l)\n",
    "                    Mijkl = Mijkl.filled_triangulation()\n",
    "                    Mijkl.dehn_fill((1,0),-1)\n",
    "                    for q in range(tries):\n",
    "                        if all_positive(Mijkl):\n",
    "                            pos_triangulations.append(Mijkl)\n",
    "                            if len(pos_triangulations)==number:\n",
    "                                return pos_triangulations\n",
    "                            break\n",
    "                        Mijkl.randomize()             \n",
    "    return pos_triangulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K7a6(0,1)\n",
      "Pos triang: []\n",
      "K11a343(0,1)\n",
      "Pos triang: []\n",
      "K11a367(0,1)\n",
      "Pos triang: []\n",
      "K12a1166(0,1)\n",
      "Pos triang: []\n",
      "K13a4878(0,1)\n",
      "Pos triang: []\n",
      "K14n21881(0,1)\n",
      "Pos triang: []\n",
      "K15a85263(0,1)\n",
      "Pos triang: []\n",
      "K15n41185(0,1)\n",
      "Pos triang: []\n",
      "--- Time taken: 0.00018204861217074923 hours ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for x in unclear_volumes:\n",
    "    K=snappy.Manifold(x[0])\n",
    "    K.dehn_fill((0,1))\n",
    "    print(K)\n",
    "    Y=find_positive_triangulations(K,number=1,tries=100)\n",
    "    print('Pos triang:',Y)\n",
    "    for X in Y:\n",
    "        vol=better_volume(K,index=1000)\n",
    "        if vol!=0:\n",
    "            more_volumes.append([x[0],vol])\n",
    "            print([x[0],vol])\n",
    "        if vol==0:\n",
    "            print('volume is still 0.')\n",
    "print(\"--- Time taken: %s hours ---\" % ((time.time() - start_time)/3600))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So they all appear to be non-hyperbolic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[s648(0,0), 7_4(0,0), K6_28(0,0), K7a6(0,0)]\n",
      "[t05803(0,0), 11_548(0,0), K8_115(0,0), K11a343(0,0)]\n",
      "[11_462(0,0), K11a367(0,0)]\n",
      "[t05899(0,0), K8_116(0,0), K12a1166(0,0)]\n",
      "[K13a4878(0,0)]\n",
      "[K14n21881(0,0)]\n",
      "[K15a85263(0,0)]\n",
      "[K15n41185(0,0)]\n"
     ]
    }
   ],
   "source": [
    "for x in unclear_volumes:\n",
    "    K=snappy.Manifold(x[0])\n",
    "    print(K.identify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['K7a6'],\n",
       " ['K11a343'],\n",
       " ['K11a367'],\n",
       " ['K12a1166'],\n",
       " ['K13a4878'],\n",
       " ['K14n21881'],\n",
       " ['K15a85263'],\n",
       " ['K15n41185']]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unclear_volumes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems they are all census knots and thus we can read-off the hyperbolicity of the filling or torus knots where we know the surgery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we work with the torus knots, from wikipedia or Dunfields [Floer homology, group orderability, and taut foliations of hyperbolic 3-manifolds] we read-off the torus knots descriptions, we save the triangulation in snappy put them manually into regina and recognize them there as the correct Seifert fibered spaces. (Although, I do not know why Dunfield's regina code does not recognizes them.)\n",
    "\n",
    "'K7a6' = census\n",
    "\n",
    "'K11a343' = census\n",
    "\n",
    "'K11a367' = T(11,2) ; 0-filling = SFS [S2: (2,1) (11,5) (22,-21)]\n",
    "\n",
    "'K12a1166' = census\n",
    "\n",
    "'K13a4878' = T(13,2) ; 0-filling = SFS [S2: (2,1) (13,6) (26,-25)]\n",
    "\n",
    "'K14n21881' = T(7,3) ; 0-filling = SFS [S2: (3,2) (7,2) (21,-20)]\n",
    "\n",
    "'K15a85263' = T(15,2) ; 0-filling = SFS [S2: (2,1) (15,7) (30,-29)]\n",
    "\n",
    "'K15n41185' = T(5,4) ; 0-filling = SFS [S2: (4,3) (5,1) (20,-19)]\n",
    "\n",
    "We add the data to the lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"regina_names.csv\", \"a\") as output: #Opens output file # Use the a parameter to add a row\n",
    "    csvwriter = csv.writer(output, delimiter = \",\")\n",
    "    csvwriter.writerow(('K11a367', 'SFS [S2: (2,1) (11,5) (22,-21)]'))\n",
    "    \n",
    "with open(\"regina_names.csv\", \"a\") as output: #Opens output file # Use the a parameter to add a row\n",
    "    csvwriter = csv.writer(output, delimiter = \",\")\n",
    "    csvwriter.writerow(('K13a4878', 'SFS [S2: (2,1) (13,6) (26,-25)]'))\n",
    "                        \n",
    "with open(\"regina_names.csv\", \"a\") as output: #Opens output file # Use the a parameter to add a row\n",
    "    csvwriter = csv.writer(output, delimiter = \",\")\n",
    "    csvwriter.writerow(('K14n21881', 'SFS [S2: (3,2) (7,2) (21,-20)]'))\n",
    "    \n",
    "with open(\"regina_names.csv\", \"a\") as output: #Opens output file # Use the a parameter to add a row\n",
    "    csvwriter = csv.writer(output, delimiter = \",\")\n",
    "    csvwriter.writerow(('K15a85263', 'SFS [S2: (2,1) (15,7) (30,-29)]'))\n",
    "                        \n",
    "with open(\"regina_names.csv\", \"a\") as output: #Opens output file # Use the a parameter to add a row\n",
    "    csvwriter = csv.writer(output, delimiter = \",\")\n",
    "    csvwriter.writerow(('K15n41185', 'SFS [S2: (4,3) (5,1) (20,-19)]'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n"
     ]
    }
   ],
   "source": [
    "regina_names=[]\n",
    "\n",
    "with open('regina_names.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        regina_names.append(row)\n",
    "print(len(regina_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['K7a6'], ['K11a343'], ['K12a1166']]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unclear_volumes=[x for x in unclear_volumes if x[0] not in [y[0] for y in regina_names]]\n",
    "unclear_volumes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last 3 are census knots. So we can check in Dunfield's list of exceptional surgeries what manifolds those are. The only slight complictation is that the slopes in Dunfield's list are measured with respect to the geometric meridian longitude basis so we need to figure out what the 0-surgery is. For that we use that the 0-filling is the unique slope that yields homology Z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[s648(0,0), 7_4(0,0), K6_28(0,0), K7a6(0,0)]\n",
      "[t05803(0,0), 11_548(0,0), K8_115(0,0), K11a343(0,0)]\n",
      "[t05899(0,0), K8_116(0,0), K12a1166(0,0)]\n"
     ]
    }
   ],
   "source": [
    "for x in unclear_volumes:\n",
    "    K=snappy.Manifold(x[0])\n",
    "    print(K.identify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Z"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K=snappy.Manifold('s648(1,1)')\n",
    "K.homology()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Z"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K=snappy.Manifold('t05803(0,1)')\n",
    "K.homology()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Z"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K=snappy.Manifold('t05899(0,1)')\n",
    "K.homology()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And from Dunfield's list we read-off:\n",
    "\n",
    "K7a6(0,1) = JSJ([('SFSpace', 'SFS [A: (2,1)]'), ('SFSpace', 'SFS [A: (2,1)]')])\n",
    "\n",
    "K11a343(0,1) = JSJ([('SFSpace', 'SFS [A: (2,1)]'), ('SFSpace', 'SFS [A: (4,7)]')])\n",
    "\n",
    "K12a1166(0,1) = JSJ([('SFSpace', 'SFS [A: (2,1)]'), ('SFSpace', 'SFS [A: (4,1)]')])\n",
    "\n",
    "We add those to the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"regina_names.csv\", \"a\") as output: #Opens output file # Use the a parameter to add a row\n",
    "    csvwriter = csv.writer(output, delimiter = \",\")\n",
    "    csvwriter.writerow(('K7a6', \"JSJ([('SFSpace', 'SFS [A: (2,1)]'), ('SFSpace', 'SFS [A: (2,1)]')])\"))\n",
    "    \n",
    "with open(\"regina_names.csv\", \"a\") as output: #Opens output file # Use the a parameter to add a row\n",
    "    csvwriter = csv.writer(output, delimiter = \",\")\n",
    "    csvwriter.writerow(('K11a343', \"JSJ([('SFSpace', 'SFS [A: (2,1)]'), ('SFSpace', 'SFS [A: (4,7)]')])\"))\n",
    "                        \n",
    "with open(\"regina_names.csv\", \"a\") as output: #Opens output file # Use the a parameter to add a row\n",
    "    csvwriter = csv.writer(output, delimiter = \",\")\n",
    "    csvwriter.writerow(('K12a1166', \"JSJ([('SFSpace', 'SFS [A: (2,1)]'), ('SFSpace', 'SFS [A: (4,1)]')])\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n"
     ]
    }
   ],
   "source": [
    "regina_names=[]\n",
    "\n",
    "with open('regina_names.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        regina_names.append(row)\n",
    "print(len(regina_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unclear_volumes=[x for x in unclear_volumes if x[0] not in [y[0] for y in regina_names]]\n",
    "unclear_volumes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This completes the classification of 0-surgeries. We sort the data and save them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['K3a1', 'SFS [S2: (2,1) (3,1) (6,-5)]'],\n",
       " ['K4a1', 'T x I / [ 2,1 | 1,1 ]'],\n",
       " ['K5a1', 'SFS [A: (2,1)] / [ 0,1 | 1,-1 ]'],\n",
       " ['K5a2', 'SFS [S2: (2,1) (5,2) (10,-9)]'],\n",
       " ['K6a3', 'SFS [A: (2,1)] / [ 0,1 | 1,-2 ]'],\n",
       " ['K7a4', 'SFS [A: (3,2)] / [ 0,1 | 1,-1 ]'],\n",
       " ['K7a6',\n",
       "  \"JSJ([('SFSpace', 'SFS [A: (2,1)]'), ('SFSpace', 'SFS [A: (2,1)]')])\"],\n",
       " ['K7a7', 'SFS [S2: (2,1) (7,3) (14,-13)]'],\n",
       " ['K8n1', 'SFS [D: (2,1) (2,1)] U/m SFS [D: (3,1) (3,2)], m = [ 0,1 | 1,0 ]'],\n",
       " ['K8n3', 'SFS [S2: (3,2) (4,1) (12,-11)]'],\n",
       " ['K8a11', 'SFS [A: (3,1)] / [ 0,1 | 1,-2 ]'],\n",
       " ['K8a18',\n",
       "  \"JSJ[('SFSpace', 'SFS [A: (2,1)]'), ('SFSpace', 'SFS [A: (2,1)]')]\"],\n",
       " ['K9n5', 'SFS [A: (2,1)] / [ -1,3 | 1,-2 ]'],\n",
       " ['K9a27', 'SFS [A: (4,3)] / [ 0,1 | 1,-1 ]'],\n",
       " ['K9a36',\n",
       "  \"JSJ[('SFSpace', 'SFS [A: (2,3)]'), ('SFSpace', 'SFS [A: (3,1)]')]\"],\n",
       " ['K9a40', \"JSJ[('hyperbolic', 'm202')]\"],\n",
       " ['K9a41', 'SFS [S2: (2,1) (9,4) (18,-17)]'],\n",
       " ['K10n13', 'SFS [S2: (2,1) (5,1) (10,-7)]'],\n",
       " ['K10n21', 'SFS [S2: (3,1) (5,3) (15,-14)]'],\n",
       " ['K10n29',\n",
       "  'SFS [D: (2,1) (2,1)] U/m SFS [D: (3,1) (3,2)], m = [ -1,2 | 0,1 ]'],\n",
       " ['K10a75', 'SFS [A: (4,1)] / [ 0,1 | 1,-2 ]'],\n",
       " ['K10a117',\n",
       "  \"JSJ[('SFSpace', 'SFS [A: (2,1)]'), ('SFSpace', 'SFS [A: (3,5)]')]\"],\n",
       " ['K11n139', 'SFS [A: (2,1)] / [ 2,5 | 1,2 ]'],\n",
       " ['K11n141', \"JSJ[('hyperbolic', 'm125')]\"],\n",
       " ['K11a247', 'SFS [A: (5,4)] / [ 0,1 | 1,-1 ]'],\n",
       " ['K11a343',\n",
       "  \"JSJ([('SFSpace', 'SFS [A: (2,1)]'), ('SFSpace', 'SFS [A: (4,7)]')])\"],\n",
       " ['K11a362', \"JSJ[('hyperbolic', 'm357')]\"],\n",
       " ['K11a363',\n",
       "  \"JSJ[('SFSpace', 'SFS [A: (3,1)]'), ('SFSpace', 'SFS [A: (3,2)]')]\"],\n",
       " ['K11a367', 'SFS [S2: (2,1) (11,5) (22,-21)]'],\n",
       " ['K12n121',\n",
       "  'SFS [D: (2,1) (2,1)] U/m SFS [D: (2,1) (3,1)], m = [ 5,1 | 4,1 ]'],\n",
       " ['K12n582',\n",
       "  'SFS [D: (2,1) (2,1)] U/m SFS [D: (3,1) (3,2)], m = [ -2,3 | -1,2 ]'],\n",
       " ['K12n721',\n",
       "  \"JSJ[('SFSpace', 'SFS [D: (2,1) (2,-1)]'), ('hyperbolic', 'm043')]\"],\n",
       " ['K12a803', 'SFS [A: (5,1)] / [ 0,1 | 1,-2 ]'],\n",
       " ['K12a1166',\n",
       "  \"JSJ([('SFSpace', 'SFS [A: (2,1)]'), ('SFSpace', 'SFS [A: (4,1)]')])\"],\n",
       " ['K12a1287',\n",
       "  \"JSJ[('SFSpace', 'SFS [A: (3,1)]'), ('SFSpace', 'SFS [A: (3,4)]')]\"],\n",
       " ['K13n469',\n",
       "  \"JSJ[('SFSpace', 'SFS [D: (2,1) (2,-1)]'), ('hyperbolic', 'm004')]\"],\n",
       " ['K13a3143', 'SFS [A: (6,5)] / [ 0,1 | 1,-1 ]'],\n",
       " ['K13n3521', \"JSJ[('hyperbolic', 'm329')]\"],\n",
       " ['K13n3523', 'SFS [A: (2,1)] / [ 2,7 | 1,3 ]'],\n",
       " ['K13n3594', \"JSJ[('hyperbolic', 'm292')]\"],\n",
       " ['K13n3596',\n",
       "  \"JSJ[('SFSpace', 'SFS [D: (2,1) (3,-2)]'), ('SFSpace', 'SFS [Or, g=0 + 3 punctures: (1,3)]')]\"],\n",
       " ['K13n3663',\n",
       "  \"JSJ[('SFSpace', 'SFS [D: (2,1) (3,-2)]'), ('SFSpace', 'SFS [Or, g=0 + 3 punctures: (1,1)]')]\"],\n",
       " ['K13a4573',\n",
       "  \"JSJ[('SFSpace', 'SFS [A: (2,1)]'), ('SFSpace', 'SFS [A: (5,4)]')]\"],\n",
       " ['K13n4587',\n",
       "  'SFS [D: (2,1) (3,1)] U/m SFS [D: (2,1) (14,1)], m = [ -3,5 | -1,2 ]'],\n",
       " ['K13n4639',\n",
       "  'SFS [D: (2,1) (3,1)] U/m SFS [D: (2,1) (10,1)], m = [ -5,7 | -2,3 ]'],\n",
       " ['K13a4843', \"JSJ[('hyperbolic', 's548')]\"],\n",
       " ['K13a4856',\n",
       "  \"JSJ[('SFSpace', 'SFS [A: (3,1)]'), ('SFSpace', 'SFS [A: (4,3)]')]\"],\n",
       " ['K13a4873', \"JSJ[('hyperbolic', 's876')]\"],\n",
       " ['K13a4878', 'SFS [S2: (2,1) (13,6) (26,-25)]'],\n",
       " ['K14n3611', \"JSJ[('SFSpace', 'M/n2 x~ S1'), ('hyperbolic', 'm015')]\"],\n",
       " ['K14a12741', 'SFS [A: (6,1)] / [ 0,1 | 1,-2 ]'],\n",
       " ['K14a17730',\n",
       "  \"JSJ[('SFSpace', 'SFS [A: (2,1)]'), ('SFSpace', 'SFS [A: (5,9)]')]\"],\n",
       " ['K14n18212',\n",
       "  'SFS [D: (2,1) (2,1)] U/m SFS [D: (3,1) (3,2)], m = [ -3,4 | -2,3 ]'],\n",
       " ['K14n19265', \"JSJ[('hyperbolic', 'v3319')]\"],\n",
       " ['K14a19429',\n",
       "  \"JSJ[('SFSpace', 'SFS [A: (3,4)]'), ('SFSpace', 'SFS [A: (4,1)]')]\"],\n",
       " ['K14n21881', 'SFS [S2: (3,2) (7,2) (21,-20)]'],\n",
       " ['K14n21882',\n",
       "  'SFS [D: (2,1) (2,1)] U/m SFS [D: (3,1) (6,1)], m = [ 1,1 | 0,1 ]'],\n",
       " ['K14n22073',\n",
       "  'SFS [D: (2,1) (3,1)] U/m SFS [A: (2,1) (2,1)] U/n SFS [D: (2,1) (3,2)], m = [ 1,-1 | 0,-1 ], n = [ 0,1 | 1,1 ]'],\n",
       " ['K14n22180',\n",
       "  \"JSJ[('SFSpace', 'SFS [D: (2,1) (3,-2)]'), ('SFSpace', 'SFS [Or, g=0 + 3 punctures: (1,1)]')]\"],\n",
       " ['K14n22185',\n",
       "  \"JSJ[('SFSpace', 'SFS [D: (2,1) (2,-1)]'), ('hyperbolic', 'm137')]\"],\n",
       " ['K14n22589', \"JSJ[('hyperbolic', 'm129')]\"],\n",
       " ['K14n24553',\n",
       "  \"JSJ[('SFSpace', 'SFS [D: (2,1) (2,-1)]'), ('hyperbolic', 's663')]\"],\n",
       " ['K14n26039',\n",
       "  \"JSJ[('SFSpace', 'Or, g=0 + 3 punctures x S1'), ('SFSpace', 'SFS [D: (2,1) (3,-2)]')]\"],\n",
       " ['K15n19499',\n",
       "  \"JSJ[('SFSpace', 'SFS [D: (2,1) (2,-1)]'), ('hyperbolic', 'm032')]\"],\n",
       " ['K15n40211',\n",
       "  'SFS [D: (2,1) (3,1)] U/m SFS [D: (2,1) (18,1)], m = [ -1,3 | 0,1 ]'],\n",
       " ['K15n41185', 'SFS [S2: (4,3) (5,1) (20,-19)]'],\n",
       " ['K15n43522', 'SFS [A: (2,1)] / [ 3,11 | 2,7 ]'],\n",
       " ['K15n48968', \"JSJ[('SFSpace', 'M/n2 x~ S1'), ('hyperbolic', 'v2817')]\"],\n",
       " ['K15n51748',\n",
       "  \"JSJ[('SFSpace', 'SFS [D: (2,1) (2,-1)]'), ('hyperbolic', 'm137')]\"],\n",
       " ['K15a54894', 'SFS [A: (7,6)] / [ 0,1 | 1,-1 ]'],\n",
       " ['K15n59184',\n",
       "  \"JSJ[('SFSpace', 'Or, g=0 + 3 punctures x S1'), ('SFSpace', 'SFS [D: (2,1) (3,-2)]')]\"],\n",
       " ['K15n72303', \"JSJ[('SFSpace', 'M/n2 x~ S1'), ('hyperbolic', 's493')]\"],\n",
       " ['K15a78880',\n",
       "  \"JSJ[('SFSpace', 'SFS [A: (2,1)]'), ('SFSpace', 'SFS [A: (6,5)]')]\"],\n",
       " ['K15a84844', \"JSJ[('hyperbolic', 'v1203')]\"],\n",
       " ['K15a84969',\n",
       "  \"JSJ[('SFSpace', 'SFS [A: (3,1)]'), ('SFSpace', 'SFS [A: (5,4)]')]\"],\n",
       " ['K15a85213', \"JSJ[('hyperbolic', 'v2601')]\"],\n",
       " ['K15a85234',\n",
       "  \"JSJ[('SFSpace', 'SFS [A: (4,1)]'), ('SFSpace', 'SFS [A: (4,7)]')]\"],\n",
       " ['K15a85257', \"JSJ[('hyperbolic', 'v3461')]\"],\n",
       " ['K15a85263', 'SFS [S2: (2,1) (15,7) (30,-29)]'],\n",
       " ['K15n112477', \"JSJ[('hyperbolic', 's503')]\"],\n",
       " ['K15n112479', 'SFS [A: (2,1)] / [ 2,9 | 1,4 ]'],\n",
       " ['K15n113773', \"JSJ[('hyperbolic', 's843')]\"],\n",
       " ['K15n113775', \"JSJ[('hyperbolic', 'm129')]\"],\n",
       " ['K15n113923', \"JSJ[('hyperbolic', 's441')]\"],\n",
       " ['K15n115375', \"JSJ[('hyperbolic', 'm129')]\"],\n",
       " ['K15n115646',\n",
       "  \"JSJ[('SFSpace', 'SFS [D: (2,1) (3,-2)]'), ('SFSpace', 'SFS [Or, g=0 + 3 punctures: (1,1)]')]\"],\n",
       " ['K15n124802',\n",
       "  'SFS [D: (2,1) (3,1)] U/m SFS [D: (2,1) (6,1)], m = [ -7,9 | -3,4 ]'],\n",
       " ['K15n142188',\n",
       "  \"JSJ[('SFSpace', 'SFS [D: (2,1) (3,-2)]'), ('hyperbolic', None)]\"],\n",
       " ['K15n153789',\n",
       "  \"JSJ[('SFSpace', 'SFS [D: (2,1) (2,-1)]'), ('hyperbolic', 'm032')]\"],\n",
       " ['K15n156076',\n",
       "  \"JSJ[('SFSpace', 'SFS [D: (2,1) (3,-2)]'), ('hyperbolic', None)]\"],\n",
       " ['K15n160926', \"JSJ[('hyperbolic', 't11128')]\"],\n",
       " ['K15n164338', \"JSJ[('hyperbolic', 's906')]\"]]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regina_names.sort(key=lambda x : (int(x[0][1:].replace('a',' ').replace('n',' ').split()[0]),int(x[0][1:].replace('a',' ').replace('n',' ').split()[1])))\n",
    "regina_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (knot, reg_name) in regina_names:\n",
    "    with open(\"regina_names.csv\", \"a\") as output: #Opens output file # Use the a parameter to add a row\n",
    "        csvwriter = csv.writer(output, delimiter = \",\")\n",
    "        csvwriter.writerow((knot, reg_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('regina_names.pickle', 'wb') as f:\n",
    "    pickle.dump(regina_names, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "volumes=volumes+more_volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313138"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(volumes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313230"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(volumes)+len(regina_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "volumes.sort(key=lambda x : (int(x[0][1:].replace('a',' ').replace('n',' ').split()[0]),int(x[0][1:].replace('a',' ').replace('n',' ').split()[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('volumes.pickle', 'wb') as f:\n",
    "    pickle.dump(volumes, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (knot, vol) in volumes:\n",
    "    with open(\"volumes.csv\", \"a\") as output: #Opens output file # Use the a parameter to add a row\n",
    "        csvwriter = csv.writer(output, delimiter = \",\")\n",
    "        csvwriter.writerow((knot, vol))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 9.0",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
